{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Valores arbitrarios\n",
    "# torch.empty(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3179, 0.2872],\n",
       "        [0.8067, 0.9225],\n",
       "        [0.8800, 0.0684]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.]],\n",
       "\n",
       "        [[1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.]],\n",
       "\n",
       "        [[1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(3, 4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(2,2, dtype = torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([100, 400, 900])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3])\n",
    "b = torch.tensor([100,200,300])\n",
    "a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([101, 202, 303])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([101, 202, 303])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.add(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "d = torch.ones(5)\n",
    "d.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1.], requires_grad=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(5, requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradientes\n",
    "x = torch.randn(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 5., 7.], requires_grad=True)\n",
      "tensor([3., 5., 7.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([3.0,5.0,7.0], requires_grad = True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 7., 9.], grad_fn=<AddBackward0>)\n",
      "tensor([5., 7., 9.], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x + 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 50.,  98., 162.], grad_fn=<MulBackward0>)\n",
      "tensor([ 50.,  98., 162.], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y=2*y*y\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entra un escalar en la segunda función"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(103.3333, grad_fn=<MeanBackward0>)\n",
      "tensor(103.3333, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y.mean()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 6.6667,  9.3333, 12.0000])\n",
      "tensor([ 6.6667,  9.3333, 12.0000])\n"
     ]
    }
   ],
   "source": [
    "z.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2361028999.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[122], line 1\u001b[1;36m\u001b[0m\n",
      "\u001b[1;33m    Posibles problemas\u001b[0m\n",
      "\u001b[1;37m             ^\u001b[0m\n",
      "\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Posibles problemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([3.0,5.0,7.0], requires_grad = True)\n",
    "y = x + 2\n",
    "y=2*y*y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#El método backward solo funciona para escalar\n",
    "#y.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segundo ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([200., 308., 432.])\n",
      "tensor([200., 308., 432.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([3.0,5.0,7.0], requires_grad = True)\n",
    "y = x + 2\n",
    "y=2*y*y\n",
    "v = torch.tensor([10, 11, 12])\n",
    "y.backward(v)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caso 3: actualizar el gradiente "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 5., 7.])\n",
      "tensor([3., 5., 7.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([3.0,5.0,7.0], requires_grad = True)\n",
    "x.requires_grad_(False)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 5., 7.])\n",
      "tensor([3., 5., 7.])\n"
     ]
    }
   ],
   "source": [
    "# Otra opción con detach\n",
    "y = x.detach()\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 7., 9.])\n",
      "tensor([5., 7., 9.])\n"
     ]
    }
   ],
   "source": [
    "# Con with torch.nograd()\n",
    "x = torch.tensor([3.0,5.0,7.0], requires_grad = True)\n",
    "with torch.no_grad():\n",
    "    y = x + 2\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(3.0)\n",
    "y = torch.tensor(14.0)\n",
    "\n",
    "w = torch.tensor(4.0, requires_grad = True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4., grad_fn=<PowBackward0>)\n",
      "tensor(4., grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y_hat = w*x\n",
    "loss = (y_hat-y)**2\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-12.)\n",
      "tensor(-12.)\n"
     ]
    }
   ],
   "source": [
    "loss.backward()\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algoritmo gradiente descendente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.array([1,2,3,4,5], dtype = np.float32)\n",
    "Y = np.array([2,4,6,8,10], dtype = np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$MSE(w_i)=\\frac{\\sum_{i=1}^n (y_i-w_ix_i)^2}{n}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora la dericada de MSE con respecto a los pesos es: $$\\frac{\\partial MSE(\\mathbf{w})}{\\partial \\mathbf{w}} = -\\frac{2}{n} \\sum_{i=1}^n (y_i - \\mathbf{w}^\\top \\mathbf{x}_i) \\mathbf{x}_i$$. Lo cual se puede expresar como -2*((y-w*x)*x).mean() o equivalentemente np.dot(-2*x, y - y_hat).mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x):\n",
    "    return w*x\n",
    "\n",
    "def loss(y, y_hat):\n",
    "    return ((y-y_hat)**2).mean() \n",
    "\n",
    "def gradient(x, y, y_hat):\n",
    "    return np.dot(-2*x, y-y_hat).mean()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1; w = 2.2\n",
      "epoch:2; w = 1.9799999618530275\n",
      "epoch:3; w = 2.0019999885559083\n",
      "epoch:4; w = 1.99979989528656\n",
      "epoch:5; w = 2.0000200200080873\n",
      "epoch:6; w = 1.9999979901313782\n",
      "epoch:7; w = 2.000000262260437\n",
      "epoch:8; w = 2.000000009536743\n",
      "epoch:9; w = 2.000000009536743\n",
      "epoch:10; w = 2.000000009536743\n",
      "epoch:1; w = 2.2\n",
      "epoch:2; w = 1.9799999618530275\n",
      "epoch:3; w = 2.0019999885559083\n",
      "epoch:4; w = 1.99979989528656\n",
      "epoch:5; w = 2.0000200200080873\n",
      "epoch:6; w = 1.9999979901313782\n",
      "epoch:7; w = 2.000000262260437\n",
      "epoch:8; w = 2.000000009536743\n",
      "epoch:9; w = 2.000000009536743\n",
      "epoch:10; w = 2.000000009536743\n"
     ]
    }
   ],
   "source": [
    "lr = 0.01 # Learning Rate\n",
    "n_iter = 10\n",
    "\n",
    "#Inicializo \n",
    "w = 0.0\n",
    "for epoch in range(n_iter):\n",
    "    y_pred = forward(X) # implicitamente está el w\n",
    "    l = loss(Y, y_pred)\n",
    "    \n",
    "    # Gradiente\n",
    "    dL_dw = gradient(X, Y, y_pred)\n",
    "    # update weights\n",
    "    w = w-lr*dL_dw\n",
    "    print(f'epoch:{epoch+1}; w = {w}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacerlo con tensor flow y usar las funcionalidades del gradiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([1,2,3,4,5], dtype = torch.float32)\n",
    "Y = torch.tensor([2,4,6,8,10], dtype = torch.float32)\n",
    "\n",
    "def forward(x):\n",
    "    return w*x\n",
    "\n",
    "def loss(y, y_hat):\n",
    "    return ((y-y_hat)**2).mean() \n",
    "\n",
    "def gradient(x, y, y_hat):\n",
    "    return np.dot(-2*x, y-y_hat).mean()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1; w = 0.4399999976158142\n",
      "epoch:11; w = 1.8699618577957153\n",
      "epoch:21; w = 1.989160418510437\n",
      "epoch:31; w = 1.9990965127944946\n",
      "epoch:41; w = 1.999924659729004\n",
      "epoch:51; w = 1.9999936819076538\n",
      "epoch:61; w = 1.9999994039535522\n",
      "epoch:71; w = 1.999999761581421\n",
      "epoch:81; w = 1.999999761581421\n",
      "epoch:91; w = 1.999999761581421\n",
      "epoch:1; w = 0.4399999976158142\n",
      "epoch:11; w = 1.8699618577957153\n",
      "epoch:21; w = 1.989160418510437\n",
      "epoch:31; w = 1.9990965127944946\n",
      "epoch:41; w = 1.999924659729004\n",
      "epoch:51; w = 1.9999936819076538\n",
      "epoch:61; w = 1.9999994039535522\n",
      "epoch:71; w = 1.999999761581421\n",
      "epoch:81; w = 1.999999761581421\n",
      "epoch:91; w = 1.999999761581421\n"
     ]
    }
   ],
   "source": [
    "lr = 0.01 # Learning Rate\n",
    "n_iter = 100\n",
    "\n",
    "#Inicializo \n",
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "for epoch in range(n_iter):\n",
    "    y_pred = forward(X) # implicitamente está el w\n",
    "    l=loss(Y, y_pred)\n",
    "    \n",
    "    # Gradiente\n",
    "    l.backward()\n",
    "    \n",
    "    # update weights\n",
    "    with torch.no_grad():\n",
    "        w -= lr * w.grad\n",
    "\n",
    "    \n",
    "    w.grad.zero_()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'epoch:{epoch+1}; w = {w}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 6.6667,  9.3333, 12.0000])\n",
      "tensor([ 6.6667,  9.3333, 12.0000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([3.0,5.0,7.0], requires_grad = True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.3887, grad_fn=<MeanBackward0>)\n",
      "tensor(8.3887, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward() #dz/dz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 5.0000, 6.9000])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,5,6.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_a = torch.arange(1, 106).reshape(3, 7, 5).float()\n",
    "\n",
    "# Generate a tensor of size 7 x 5 with a sequence from 100 to 134\n",
    "tensor_b = torch.arange(100, 135).reshape(7, 5).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[  1.,   2.,   3.,   4.,   5.],\n",
      "         [  6.,   7.,   8.,   9.,  10.],\n",
      "         [ 11.,  12.,  13.,  14.,  15.],\n",
      "         [ 16.,  17.,  18.,  19.,  20.],\n",
      "         [ 21.,  22.,  23.,  24.,  25.],\n",
      "         [ 26.,  27.,  28.,  29.,  30.],\n",
      "         [ 31.,  32.,  33.,  34.,  35.]],\n",
      "\n",
      "        [[ 36.,  37.,  38.,  39.,  40.],\n",
      "         [ 41.,  42.,  43.,  44.,  45.],\n",
      "         [ 46.,  47.,  48.,  49.,  50.],\n",
      "         [ 51.,  52.,  53.,  54.,  55.],\n",
      "         [ 56.,  57.,  58.,  59.,  60.],\n",
      "         [ 61.,  62.,  63.,  64.,  65.],\n",
      "         [ 66.,  67.,  68.,  69.,  70.]],\n",
      "\n",
      "        [[ 71.,  72.,  73.,  74.,  75.],\n",
      "         [ 76.,  77.,  78.,  79.,  80.],\n",
      "         [ 81.,  82.,  83.,  84.,  85.],\n",
      "         [ 86.,  87.,  88.,  89.,  90.],\n",
      "         [ 91.,  92.,  93.,  94.,  95.],\n",
      "         [ 96.,  97.,  98.,  99., 100.],\n",
      "         [101., 102., 103., 104., 105.]]])\n",
      "tensor([[[  1.,   2.,   3.,   4.,   5.],\n",
      "         [  6.,   7.,   8.,   9.,  10.],\n",
      "         [ 11.,  12.,  13.,  14.,  15.],\n",
      "         [ 16.,  17.,  18.,  19.,  20.],\n",
      "         [ 21.,  22.,  23.,  24.,  25.],\n",
      "         [ 26.,  27.,  28.,  29.,  30.],\n",
      "         [ 31.,  32.,  33.,  34.,  35.]],\n",
      "\n",
      "        [[ 36.,  37.,  38.,  39.,  40.],\n",
      "         [ 41.,  42.,  43.,  44.,  45.],\n",
      "         [ 46.,  47.,  48.,  49.,  50.],\n",
      "         [ 51.,  52.,  53.,  54.,  55.],\n",
      "         [ 56.,  57.,  58.,  59.,  60.],\n",
      "         [ 61.,  62.,  63.,  64.,  65.],\n",
      "         [ 66.,  67.,  68.,  69.,  70.]],\n",
      "\n",
      "        [[ 71.,  72.,  73.,  74.,  75.],\n",
      "         [ 76.,  77.,  78.,  79.,  80.],\n",
      "         [ 81.,  82.,  83.,  84.,  85.],\n",
      "         [ 86.,  87.,  88.,  89.,  90.],\n",
      "         [ 91.,  92.,  93.,  94.,  95.],\n",
      "         [ 96.,  97.,  98.,  99., 100.],\n",
      "         [101., 102., 103., 104., 105.]]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[100., 101., 102., 103., 104.],\n",
      "        [105., 106., 107., 108., 109.],\n",
      "        [110., 111., 112., 113., 114.],\n",
      "        [115., 116., 117., 118., 119.],\n",
      "        [120., 121., 122., 123., 124.],\n",
      "        [125., 126., 127., 128., 129.],\n",
      "        [130., 131., 132., 133., 134.]])\n",
      "tensor([[100., 101., 102., 103., 104.],\n",
      "        [105., 106., 107., 108., 109.],\n",
      "        [110., 111., 112., 113., 114.],\n",
      "        [115., 116., 117., 118., 119.],\n",
      "        [120., 121., 122., 123., 124.],\n",
      "        [125., 126., 127., 128., 129.],\n",
      "        [130., 131., 132., 133., 134.]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[101., 103., 105., 107., 109.],\n",
      "         [111., 113., 115., 117., 119.],\n",
      "         [121., 123., 125., 127., 129.],\n",
      "         [131., 133., 135., 137., 139.],\n",
      "         [141., 143., 145., 147., 149.],\n",
      "         [151., 153., 155., 157., 159.],\n",
      "         [161., 163., 165., 167., 169.]],\n",
      "\n",
      "        [[136., 138., 140., 142., 144.],\n",
      "         [146., 148., 150., 152., 154.],\n",
      "         [156., 158., 160., 162., 164.],\n",
      "         [166., 168., 170., 172., 174.],\n",
      "         [176., 178., 180., 182., 184.],\n",
      "         [186., 188., 190., 192., 194.],\n",
      "         [196., 198., 200., 202., 204.]],\n",
      "\n",
      "        [[171., 173., 175., 177., 179.],\n",
      "         [181., 183., 185., 187., 189.],\n",
      "         [191., 193., 195., 197., 199.],\n",
      "         [201., 203., 205., 207., 209.],\n",
      "         [211., 213., 215., 217., 219.],\n",
      "         [221., 223., 225., 227., 229.],\n",
      "         [231., 233., 235., 237., 239.]]])\n",
      "tensor([[[101., 103., 105., 107., 109.],\n",
      "         [111., 113., 115., 117., 119.],\n",
      "         [121., 123., 125., 127., 129.],\n",
      "         [131., 133., 135., 137., 139.],\n",
      "         [141., 143., 145., 147., 149.],\n",
      "         [151., 153., 155., 157., 159.],\n",
      "         [161., 163., 165., 167., 169.]],\n",
      "\n",
      "        [[136., 138., 140., 142., 144.],\n",
      "         [146., 148., 150., 152., 154.],\n",
      "         [156., 158., 160., 162., 164.],\n",
      "         [166., 168., 170., 172., 174.],\n",
      "         [176., 178., 180., 182., 184.],\n",
      "         [186., 188., 190., 192., 194.],\n",
      "         [196., 198., 200., 202., 204.]],\n",
      "\n",
      "        [[171., 173., 175., 177., 179.],\n",
      "         [181., 183., 185., 187., 189.],\n",
      "         [191., 193., 195., 197., 199.],\n",
      "         [201., 203., 205., 207., 209.],\n",
      "         [211., 213., 215., 217., 219.],\n",
      "         [221., 223., 225., 227., 229.],\n",
      "         [231., 233., 235., 237., 239.]]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(tensor_a + tensor_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro ejemplo de broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Generate a tensor of size 3 x 7 x 1 with a sequence from 1 to 21\n",
    "tensor_c = torch.arange(1, 22).reshape(3, 7, 1).float()\n",
    "\n",
    "# Generate a tensor of size 1 x 5 with a sequence from 100 to 104\n",
    "tensor_d = torch.arange(100, 105).reshape(1, 5).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.],\n",
      "         [ 2.],\n",
      "         [ 3.],\n",
      "         [ 4.],\n",
      "         [ 5.],\n",
      "         [ 6.],\n",
      "         [ 7.]],\n",
      "\n",
      "        [[ 8.],\n",
      "         [ 9.],\n",
      "         [10.],\n",
      "         [11.],\n",
      "         [12.],\n",
      "         [13.],\n",
      "         [14.]],\n",
      "\n",
      "        [[15.],\n",
      "         [16.],\n",
      "         [17.],\n",
      "         [18.],\n",
      "         [19.],\n",
      "         [20.],\n",
      "         [21.]]])\n",
      "tensor([[[ 1.],\n",
      "         [ 2.],\n",
      "         [ 3.],\n",
      "         [ 4.],\n",
      "         [ 5.],\n",
      "         [ 6.],\n",
      "         [ 7.]],\n",
      "\n",
      "        [[ 8.],\n",
      "         [ 9.],\n",
      "         [10.],\n",
      "         [11.],\n",
      "         [12.],\n",
      "         [13.],\n",
      "         [14.]],\n",
      "\n",
      "        [[15.],\n",
      "         [16.],\n",
      "         [17.],\n",
      "         [18.],\n",
      "         [19.],\n",
      "         [20.],\n",
      "         [21.]]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[100., 101., 102., 103., 104.]])\n",
      "tensor([[100., 101., 102., 103., 104.]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[101., 102., 103., 104., 105.],\n",
      "         [102., 103., 104., 105., 106.],\n",
      "         [103., 104., 105., 106., 107.],\n",
      "         [104., 105., 106., 107., 108.],\n",
      "         [105., 106., 107., 108., 109.],\n",
      "         [106., 107., 108., 109., 110.],\n",
      "         [107., 108., 109., 110., 111.]],\n",
      "\n",
      "        [[108., 109., 110., 111., 112.],\n",
      "         [109., 110., 111., 112., 113.],\n",
      "         [110., 111., 112., 113., 114.],\n",
      "         [111., 112., 113., 114., 115.],\n",
      "         [112., 113., 114., 115., 116.],\n",
      "         [113., 114., 115., 116., 117.],\n",
      "         [114., 115., 116., 117., 118.]],\n",
      "\n",
      "        [[115., 116., 117., 118., 119.],\n",
      "         [116., 117., 118., 119., 120.],\n",
      "         [117., 118., 119., 120., 121.],\n",
      "         [118., 119., 120., 121., 122.],\n",
      "         [119., 120., 121., 122., 123.],\n",
      "         [120., 121., 122., 123., 124.],\n",
      "         [121., 122., 123., 124., 125.]]])\n",
      "tensor([[[101., 102., 103., 104., 105.],\n",
      "         [102., 103., 104., 105., 106.],\n",
      "         [103., 104., 105., 106., 107.],\n",
      "         [104., 105., 106., 107., 108.],\n",
      "         [105., 106., 107., 108., 109.],\n",
      "         [106., 107., 108., 109., 110.],\n",
      "         [107., 108., 109., 110., 111.]],\n",
      "\n",
      "        [[108., 109., 110., 111., 112.],\n",
      "         [109., 110., 111., 112., 113.],\n",
      "         [110., 111., 112., 113., 114.],\n",
      "         [111., 112., 113., 114., 115.],\n",
      "         [112., 113., 114., 115., 116.],\n",
      "         [113., 114., 115., 116., 117.],\n",
      "         [114., 115., 116., 117., 118.]],\n",
      "\n",
      "        [[115., 116., 117., 118., 119.],\n",
      "         [116., 117., 118., 119., 120.],\n",
      "         [117., 118., 119., 120., 121.],\n",
      "         [118., 119., 120., 121., 122.],\n",
      "         [119., 120., 121., 122., 123.],\n",
      "         [120., 121., 122., 123., 124.],\n",
      "         [121., 122., 123., 124., 125.]]])\n"
     ]
    }
   ],
   "source": [
    "# Broadcast tensor_b to match the shape of tensor_a and perform an operation, e.g., addition\n",
    "print(tensor_c + tensor_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[36], line 1\u001b[0m\n",
      "\u001b[1;32m----> 1\u001b[0m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39madd(torch\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n",
      "\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    " torch.zeros(4, 3, 2, 1).add(torch.ones(4, 3, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
