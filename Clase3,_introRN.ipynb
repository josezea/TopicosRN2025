{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4dR505UWfrya",
        "outputId": "169b52d2-92c9-4ab1-bca9-f6e514bbf78a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
              "0                5.1               3.5                1.4               0.2   \n",
              "1                4.9               3.0                1.4               0.2   \n",
              "2                4.7               3.2                1.3               0.2   \n",
              "3                4.6               3.1                1.5               0.2   \n",
              "4                5.0               3.6                1.4               0.2   \n",
              "\n",
              "  species  \n",
              "0  setosa  \n",
              "1  setosa  \n",
              "2  setosa  \n",
              "3  setosa  \n",
              "4  setosa  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ed9abc15-6868-4bf9-a4cc-a2d6025f27ca\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ed9abc15-6868-4bf9-a4cc-a2d6025f27ca')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ed9abc15-6868-4bf9-a4cc-a2d6025f27ca button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ed9abc15-6868-4bf9-a4cc-a2d6025f27ca');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7a31d36d-5ae0-4697-b860-fc7c697bdd49\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7a31d36d-5ae0-4697-b860-fc7c697bdd49')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7a31d36d-5ae0-4697-b860-fc7c697bdd49 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 150,\n  \"fields\": [\n    {\n      \"column\": \"sepal length (cm)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8280661279778629,\n        \"min\": 4.3,\n        \"max\": 7.9,\n        \"num_unique_values\": 35,\n        \"samples\": [\n          6.2,\n          4.5,\n          5.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sepal width (cm)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.435866284936698,\n        \"min\": 2.0,\n        \"max\": 4.4,\n        \"num_unique_values\": 23,\n        \"samples\": [\n          2.3,\n          4.0,\n          3.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"petal length (cm)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.7652982332594667,\n        \"min\": 1.0,\n        \"max\": 6.9,\n        \"num_unique_values\": 43,\n        \"samples\": [\n          6.7,\n          3.8,\n          3.7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"petal width (cm)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7622376689603465,\n        \"min\": 0.1,\n        \"max\": 2.5,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          0.2,\n          1.2,\n          1.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"species\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"setosa\",\n          \"versicolor\",\n          \"virginica\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "from sklearn import datasets\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Cargar el dataset Iris\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "# Convertirlo a un DataFrame de pandas\n",
        "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "df['species'] = iris.target  # Agregar la columna de etiquetas numéricas\n",
        "df['species'] = df['species'].map({0: 'setosa', 1: 'versicolor', 2: 'virginica'})  # Convertir a nombres de especies\n",
        "N = df.shape[0]\n",
        "# Mostrar las primeras filas\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "N"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14KUUZmif9nJ",
        "outputId": "99798de7-e92b-4010-d725-381fa128848a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "150"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Extraer las columnas usando NumPy\n",
        "import numpy as np\n",
        "x = np.array(df['petal length (cm)'])  # Definir x como petal length\n",
        "y = np.array(df['petal width (cm)'])   # Definir y como petal width\n",
        "\n",
        "# Mostrar los primeros valores\n",
        "print(\"x (Petal Length):\", x[:5])\n",
        "print(\"y (Petal Width):\", y[:5])\n",
        "\n",
        "# Mezcla los índices\n",
        "idx = np.arange(N)\n",
        "np.random.shuffle(idx)\n",
        "\n",
        "# Usa los primeros 80% de índices para entrenamiento\n",
        "train_idx = idx[:int(N * 0.8)]\n",
        "# Usa el 20% restante para validación\n",
        "val_idx = idx[int(N * 0.8):]\n",
        "\n",
        "# Generar los conjuntos de entrenamiento y validación\n",
        "x_train, y_train = x[train_idx], y[train_idx]\n",
        "x_val, y_val = x[val_idx], y[val_idx]\n",
        "\n",
        "# Mostrar tamaños de los conjuntos\n",
        "print(f\"Train set: {x_train.shape}, {y_train.shape}\")\n",
        "print(f\"Validation set: {x_val.shape}, {y_val.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5CJaTQwgPEI",
        "outputId": "d2132037-e9ff-4ca6-b181-6a088d164b7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x (Petal Length): [1.4 1.4 1.3 1.5 1.4]\n",
            "y (Petal Width): [0.2 0.2 0.2 0.2 0.2]\n",
            "Train set: (120,), (120,)\n",
            "Validation set: (30,), (30,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fase de entrenamiento\n"
      ],
      "metadata": {
        "id": "kBrNR19Ag1-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x_train_tensor = torch.as_tensor(x_train)\n",
        "y_train_tensor = torch.as_tensor(y_train)\n",
        "\n",
        "\n",
        "device = 'cpu'\n"
      ],
      "metadata": {
        "id": "sDXBPBUJhW64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Supongamos que x_train_tensor y y_train_tensor están definidos\n",
        "# y tienen la misma cantidad de elementos\n",
        "\n",
        "# Define la tasa de aprendizaje\n",
        "lr = 0.001\n",
        "\n",
        "# Número de épocas\n",
        "n_epochs = 1000\n",
        "\n",
        "# Inicialización de parámetros\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "w = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "\n",
        "# Bucle de entrenamiento\n",
        "for epoch in range(n_epochs):\n",
        "    for i in range(len(x_train_tensor)):  # Iteramos sobre cada punto de datos\n",
        "        x_i = x_train_tensor[i]  # Seleccionamos un solo punto x\n",
        "        y_i = y_train_tensor[i]  # Seleccionamos su correspondiente y\n",
        "\n",
        "        # Paso 1: Predicción del modelo\n",
        "        yhat = b + w * x_i\n",
        "\n",
        "        # Paso 2: Cálculo de la pérdida (error cuadrático medio para un solo punto)\n",
        "        loss = (yhat - y_i) ** 2\n",
        "\n",
        "        # Paso 3: Cálculo de gradientes\n",
        "        loss.backward()\n",
        "\n",
        "        # Paso 4: Actualización de parámetros\n",
        "        with torch.no_grad():\n",
        "            b -= lr * b.grad\n",
        "            w -= lr * w.grad\n",
        "\n",
        "        # Limpiar gradientes antes de la siguiente iteración\n",
        "        b.grad.zero_()\n",
        "        w.grad.zero_()\n",
        "\n",
        "    # Imprimir cada 50 épocas\n",
        "    #if (epoch + 1) % 50 == 0:\n",
        "    if (epoch + 1) in [1, 10, 30] or (epoch + 1) % 50 == 0:\n",
        "        print(f\"Época {epoch+1}: b = {b.item()}, w = {w.item()}, pérdida = {loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wY3nzc4MgxW5",
        "outputId": "4a4c3288-5b50-4fe2-ec43-c32c3d4f7655"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Época 1: b = -0.6071049571037292, w = 0.4596485495567322, pérdida = 0.06593582779169083\n",
            "Época 10: b = -0.5423060059547424, w = 0.45591437816619873, pérdida = 0.03848109766840935\n",
            "Época 30: b = -0.45921024680137634, w = 0.4379741847515106, pérdida = 0.01803557202219963\n",
            "Época 50: b = -0.41937655210494995, w = 0.42937415838241577, pérdida = 0.0109491478651762\n",
            "Época 100: b = -0.38853487372398376, w = 0.42271554470062256, pérdida = 0.006670767907053232\n",
            "Época 150: b = -0.38362768292427063, w = 0.4216560423374176, pérdida = 0.00608730036765337\n",
            "Época 200: b = -0.3828471302986145, w = 0.42148762941360474, pérdida = 0.00599692715331912\n",
            "Época 250: b = -0.3827223479747772, w = 0.42146068811416626, pérdida = 0.005982557777315378\n",
            "Época 300: b = -0.3827029764652252, w = 0.42145639657974243, pérdida = 0.005980340298265219\n",
            "Época 350: b = -0.3827022910118103, w = 0.4214562773704529, pérdida = 0.005980262067168951\n",
            "Época 400: b = -0.3827022910118103, w = 0.4214562773704529, pérdida = 0.005980262067168951\n",
            "Época 450: b = -0.3827022910118103, w = 0.4214562773704529, pérdida = 0.005980262067168951\n",
            "Época 500: b = -0.3827022910118103, w = 0.4214562773704529, pérdida = 0.005980262067168951\n",
            "Época 550: b = -0.3827022910118103, w = 0.4214562773704529, pérdida = 0.005980262067168951\n",
            "Época 600: b = -0.3827022910118103, w = 0.4214562773704529, pérdida = 0.005980262067168951\n",
            "Época 650: b = -0.3827022910118103, w = 0.4214562773704529, pérdida = 0.005980262067168951\n",
            "Época 700: b = -0.3827022910118103, w = 0.4214562773704529, pérdida = 0.005980262067168951\n",
            "Época 750: b = -0.3827022910118103, w = 0.4214562773704529, pérdida = 0.005980262067168951\n",
            "Época 800: b = -0.3827022910118103, w = 0.4214562773704529, pérdida = 0.005980262067168951\n",
            "Época 850: b = -0.3827022910118103, w = 0.4214562773704529, pérdida = 0.005980262067168951\n",
            "Época 900: b = -0.3827022910118103, w = 0.4214562773704529, pérdida = 0.005980262067168951\n",
            "Época 950: b = -0.3827022910118103, w = 0.4214562773704529, pérdida = 0.005980262067168951\n",
            "Época 1000: b = -0.3827022910118103, w = 0.4214562773704529, pérdida = 0.005980262067168951\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "# Realizar la regresión lineal\n",
        "slope, intercept, r_value, p_value, std_err = stats.linregress(x_train, y_train)\n",
        "\n",
        "# Mostrar los resultados\n",
        "print(f\"Coeficiente de pendiente (w): {slope}\")\n",
        "print(f\"Coeficiente de intercepción (b): {intercept}\")\n",
        "print(f\"Coeficiente de correlación (r): {r_value}\")\n",
        "print(f\"Valor p: {p_value}\")\n",
        "print(f\"Error estándar: {std_err}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBQAlTHHqAOo",
        "outputId": "d2187178-27a6-4171-e190-78047cbe4fed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coeficiente de pendiente (w): 0.41978267197769203\n",
            "Coeficiente de intercepción (b): -0.3803812215275777\n",
            "Coeficiente de correlación (r): 0.9581396637068823\n",
            "Valor p: 6.144178910344734e-66\n",
            "Error estándar: 0.011547231530290233\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z5KPZC6mqAHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradiente descendete (la palabra estocastico no va)"
      ],
      "metadata": {
        "id": "pz0ZlhZSrmuB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "lr = 0.01\n",
        "\n",
        "# Step 0 - Initializes parameters \"b\" and \"w\" randomly\n",
        "torch.manual_seed(42)\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "w = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "(b, w)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HX4geobqFMS",
        "outputId": "14ad48e9-5d7e-4b92-b13e-c7cc0a59b677"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.3367], requires_grad=True), tensor([0.1288], requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Supongamos que x_train_tensor y y_train_tensor están definidos\n",
        "# y tienen la misma cantidad de elementos\n",
        "\n",
        "# Define la tasa de aprendizaje\n",
        "lr = 0.001\n",
        "\n",
        "# Número de épocas\n",
        "n_epochs = 31000\n",
        "\n",
        "# Inicialización de parámetros\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "w = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    # Step 1 - Computes model's predicted output - forward pass\n",
        "    yhat = b + w * x_train_tensor\n",
        "\n",
        "    # Step 2 - Computes the loss\n",
        "    # We are using ALL data points, so this is BATCH gradient\n",
        "    # descent. How wrong is our model? That's the error!\n",
        "    error = (yhat - y_train_tensor)\n",
        "    # It is a regression, so it computes mean squared error (MSE)\n",
        "    loss = (error ** 2).mean()\n",
        "\n",
        "    # Step 3 - Computes gradients for both \"b\" and \"w\"\n",
        "    loss.backward()\n",
        "\n",
        "    # Step 4 - Updates parameters using gradients and\n",
        "    # the learning rate.\n",
        "    with torch.no_grad():\n",
        "        b -= lr * b.grad # b = b -lr * b.grad\n",
        "        w -= lr * w.grad\n",
        "\n",
        "    # Clears gradients\n",
        "    b.grad.zero_()\n",
        "    w.grad.zero_()\n",
        "\n",
        "    # Prints values every 50 iterations\n",
        "    if (epoch + 1) in [1, 10, 30] or (epoch + 1) % 50 == 0:\n",
        "        print(f\"Epoch {epoch+1}: b = {b.item()}, w = {w.item()}, loss = {loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AF3Rhzl4r2F7",
        "outputId": "64a78b46-3caa-493a-fee9-3f296ce8cc44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: b = 0.23468923568725586, w = 0.23227083683013916, loss = 0.15806939911097675\n",
            "Epoch 10: b = 0.23610414564609528, w = 0.24685508012771606, loss = 0.1326122135872609\n",
            "Epoch 30: b = 0.2364180088043213, w = 0.2663455307483673, loss = 0.11165447485945713\n",
            "Epoch 50: b = 0.23458245396614075, w = 0.27597612142562866, loss = 0.10641250439798669\n",
            "Epoch 100: b = 0.22671200335025787, w = 0.2846895158290863, loss = 0.10332704513391583\n",
            "Epoch 150: b = 0.21773993968963623, w = 0.28773370385169983, loss = 0.10152326742886333\n",
            "Epoch 200: b = 0.2087172269821167, w = 0.28988566994667053, loss = 0.09980146427627391\n",
            "Epoch 250: b = 0.1998026967048645, w = 0.29187580943107605, loss = 0.09813206166491187\n",
            "Epoch 300: b = 0.1910187304019928, w = 0.29381605982780457, loss = 0.09651283763783525\n",
            "Epoch 350: b = 0.18236707150936127, w = 0.29572388529777527, loss = 0.09494227571641446\n",
            "Epoch 400: b = 0.17384639382362366, w = 0.2976023852825165, loss = 0.09341892358040899\n",
            "Epoch 450: b = 0.1654546707868576, w = 0.29945236444473267, loss = 0.09194134776883513\n",
            "Epoch 500: b = 0.1571899950504303, w = 0.3012743294239044, loss = 0.09050817755161814\n",
            "Epoch 550: b = 0.14905045926570892, w = 0.30306869745254517, loss = 0.08911807688489272\n",
            "Epoch 600: b = 0.14103417098522186, w = 0.30483588576316833, loss = 0.08776975635694555\n",
            "Epoch 650: b = 0.1331392228603363, w = 0.30657634139060974, loss = 0.08646194931574941\n",
            "Epoch 700: b = 0.12536382675170898, w = 0.3082904517650604, loss = 0.08519344999273905\n",
            "Epoch 750: b = 0.11770618706941605, w = 0.30997854471206665, loss = 0.08396307853460226\n",
            "Epoch 800: b = 0.11016449332237244, w = 0.3116410970687866, loss = 0.08276968298187458\n",
            "Epoch 850: b = 0.10273701697587967, w = 0.3132784962654114, loss = 0.08161215615556681\n",
            "Epoch 900: b = 0.09542200714349747, w = 0.31489112973213196, loss = 0.08048941698847452\n",
            "Epoch 950: b = 0.08821770548820496, w = 0.3164793848991394, loss = 0.07940041149993264\n",
            "Epoch 1000: b = 0.08112248033285141, w = 0.3180435001850128, loss = 0.0783441356237376\n",
            "Epoch 1050: b = 0.0741347149014473, w = 0.3195839822292328, loss = 0.07731960729100967\n",
            "Epoch 1100: b = 0.0672527477145195, w = 0.3211011290550232, loss = 0.0763258693529632\n",
            "Epoch 1150: b = 0.06047496199607849, w = 0.3225952982902527, loss = 0.07536199314005453\n",
            "Epoch 1200: b = 0.0537998341023922, w = 0.32406678795814514, loss = 0.07442709119902556\n",
            "Epoch 1250: b = 0.04722575843334198, w = 0.32551610469818115, loss = 0.07352028039105113\n",
            "Epoch 1300: b = 0.040751226246356964, w = 0.32694339752197266, loss = 0.07264072607021982\n",
            "Epoch 1350: b = 0.03437472879886627, w = 0.3283490836620331, loss = 0.07178760391407266\n",
            "Epoch 1400: b = 0.028094787150621414, w = 0.32973355054855347, loss = 0.07096012121388778\n",
            "Epoch 1450: b = 0.021909918636083603, w = 0.3310970067977905, loss = 0.07015750627301806\n",
            "Epoch 1500: b = 0.015818698331713676, w = 0.3324398398399353, loss = 0.06937901217551672\n",
            "Epoch 1550: b = 0.009819711558520794, w = 0.3337622880935669, loss = 0.06862391696545869\n",
            "Epoch 1600: b = 0.003911563660949469, w = 0.33506476879119873, loss = 0.0678915141101375\n",
            "Epoch 1650: b = -0.0019071275601163507, w = 0.3363474905490875, loss = 0.0671811223442356\n",
            "Epoch 1700: b = -0.007637720089405775, w = 0.33761081099510193, loss = 0.06649207989511921\n",
            "Epoch 1750: b = -0.013281538151204586, w = 0.33885499835014343, loss = 0.06582374676032325\n",
            "Epoch 1800: b = -0.018839891999959946, w = 0.34008029103279114, loss = 0.06517550080681868\n",
            "Epoch 1850: b = -0.024314099922776222, w = 0.34128719568252563, loss = 0.0645467320447147\n",
            "Epoch 1900: b = -0.029705433174967766, w = 0.3424757122993469, loss = 0.06393686088897517\n",
            "Epoch 1950: b = -0.035015132278203964, w = 0.34364622831344604, loss = 0.0633453189732949\n",
            "Epoch 2000: b = -0.04024442657828331, w = 0.3447990417480469, loss = 0.06277155480895517\n",
            "Epoch 2050: b = -0.045394547283649445, w = 0.34593436121940613, loss = 0.06221503465107509\n",
            "Epoch 2100: b = -0.050466686487197876, w = 0.34705251455307007, loss = 0.06167524022398163\n",
            "Epoch 2150: b = -0.055462028831243515, w = 0.3481537699699402, loss = 0.06115166731006512\n",
            "Epoch 2200: b = -0.060381755232810974, w = 0.3492383360862732, loss = 0.06064382707196137\n",
            "Epoch 2250: b = -0.06522698700428009, w = 0.3503064513206482, loss = 0.06015125026651488\n",
            "Epoch 2300: b = -0.0699988380074501, w = 0.35135841369628906, loss = 0.059673479549956915\n",
            "Epoch 2350: b = -0.07469842582941055, w = 0.3523944616317749, loss = 0.059210066829323615\n",
            "Epoch 2400: b = -0.07932687550783157, w = 0.3534148037433624, loss = 0.05876058102338866\n",
            "Epoch 2450: b = -0.08388523012399673, w = 0.35441967844963074, loss = 0.05832460416824683\n",
            "Epoch 2500: b = -0.088374562561512, w = 0.35540932416915894, loss = 0.05790173099652367\n",
            "Epoch 2550: b = -0.09279591590166092, w = 0.3563840091228485, loss = 0.057491566574292025\n",
            "Epoch 2600: b = -0.09715032577514648, w = 0.35734403133392334, loss = 0.05709372707989935\n",
            "Epoch 2650: b = -0.10143879055976868, w = 0.3582894206047058, loss = 0.056707847022881584\n",
            "Epoch 2700: b = -0.10566235333681107, w = 0.3592205047607422, loss = 0.05633356073858917\n",
            "Epoch 2750: b = -0.10982196033000946, w = 0.3601374924182892, loss = 0.055970524154180044\n",
            "Epoch 2800: b = -0.11391857266426086, w = 0.3610405921936035, loss = 0.055618398715533715\n",
            "Epoch 2850: b = -0.11795317381620407, w = 0.3619300425052643, loss = 0.05527685370224462\n",
            "Epoch 2900: b = -0.1219266876578331, w = 0.3628059923648834, loss = 0.05494557385917478\n",
            "Epoch 2950: b = -0.12584002315998077, w = 0.3636687099933624, loss = 0.05462425083899188\n",
            "Epoch 3000: b = -0.1296941190958023, w = 0.36451831459999084, loss = 0.05431258423016414\n",
            "Epoch 3050: b = -0.13348984718322754, w = 0.36535510420799255, loss = 0.0540102851622832\n",
            "Epoch 3100: b = -0.1372281014919281, w = 0.3661791682243347, loss = 0.05371707133826944\n",
            "Epoch 3150: b = -0.140909805893898, w = 0.3669908046722412, loss = 0.05343266579901861\n",
            "Epoch 3200: b = -0.14453573524951935, w = 0.36779022216796875, loss = 0.05315680688766255\n",
            "Epoch 3250: b = -0.14810675382614136, w = 0.36857742071151733, loss = 0.05288924229917448\n",
            "Epoch 3300: b = -0.1516236811876297, w = 0.3693527281284332, loss = 0.05262971981527108\n",
            "Epoch 3350: b = -0.15508735179901123, w = 0.37011632323265076, loss = 0.05237799714012336\n",
            "Epoch 3400: b = -0.158498615026474, w = 0.3708683252334595, loss = 0.052133836943329785\n",
            "Epoch 3450: b = -0.1618582159280777, w = 0.3716089427471161, loss = 0.05189701621217436\n",
            "Epoch 3500: b = -0.1651669442653656, w = 0.37233835458755493, loss = 0.051667312238144046\n",
            "Epoch 3550: b = -0.1684255748987198, w = 0.3730567395687103, loss = 0.05144451084736423\n",
            "Epoch 3600: b = -0.17163485288619995, w = 0.3737642168998718, loss = 0.05122840699309446\n",
            "Epoch 3650: b = -0.17479553818702698, w = 0.37446102499961853, loss = 0.05101879807668823\n",
            "Epoch 3700: b = -0.17790837585926056, w = 0.3751472234725952, loss = 0.05081548789474295\n",
            "Epoch 3750: b = -0.18097412586212158, w = 0.37582308053970337, loss = 0.050618284474845156\n",
            "Epoch 3800: b = -0.1839934140443802, w = 0.37648868560791016, loss = 0.05042701051365371\n",
            "Epoch 3850: b = -0.18696698546409607, w = 0.3771442174911499, loss = 0.05024148536667187\n",
            "Epoch 3900: b = -0.18989552557468414, w = 0.37778982520103455, loss = 0.05006153594390113\n",
            "Epoch 3950: b = -0.19277971982955933, w = 0.378425657749176, loss = 0.049886995242065905\n",
            "Epoch 4000: b = -0.19562026858329773, w = 0.3790518343448639, loss = 0.049717698697459824\n",
            "Epoch 4050: b = -0.1984177827835083, w = 0.37966856360435486, loss = 0.0495534914909589\n",
            "Epoch 4100: b = -0.20117293298244476, w = 0.38027599453926086, loss = 0.04939421836336448\n",
            "Epoch 4150: b = -0.20388637483119965, w = 0.3808741271495819, loss = 0.04923973321410554\n",
            "Epoch 4200: b = -0.2065587192773819, w = 0.38146325945854187, loss = 0.04908989049674374\n",
            "Epoch 4250: b = -0.20919062197208405, w = 0.3820434510707855, loss = 0.04894455028084734\n",
            "Epoch 4300: b = -0.21178266406059265, w = 0.3826148808002472, loss = 0.04880357873653571\n",
            "Epoch 4350: b = -0.21433547139167786, w = 0.38317760825157166, loss = 0.048666843585487424\n",
            "Epoch 4400: b = -0.21684959530830383, w = 0.383731871843338, loss = 0.04853421806721121\n",
            "Epoch 4450: b = -0.21932579576969147, w = 0.38427773118019104, loss = 0.04840557263110384\n",
            "Epoch 4500: b = -0.22176437079906464, w = 0.3848153352737427, loss = 0.048280798921872425\n",
            "Epoch 4550: b = -0.22416606545448303, w = 0.38534483313560486, loss = 0.04815977242484839\n",
            "Epoch 4600: b = -0.22653143107891083, w = 0.3858662545681, loss = 0.048042382685218855\n",
            "Epoch 4650: b = -0.22886089980602264, w = 0.38637977838516235, loss = 0.04792852454485672\n",
            "Epoch 4700: b = -0.23115509748458862, w = 0.38688552379608154, loss = 0.04781808839617168\n",
            "Epoch 4750: b = -0.23341457545757294, w = 0.3873836398124695, loss = 0.04771097031698195\n",
            "Epoch 4800: b = -0.2356397956609726, w = 0.38787418603897095, loss = 0.04760707332843426\n",
            "Epoch 4850: b = -0.23783136904239655, w = 0.38835734128952026, loss = 0.047506297238325265\n",
            "Epoch 4900: b = -0.2399897575378418, w = 0.3888331651687622, loss = 0.04740854893394862\n",
            "Epoch 4950: b = -0.24211546778678894, w = 0.38930177688598633, loss = 0.047313739070815104\n",
            "Epoch 5000: b = -0.24420897662639618, w = 0.3897632956504822, loss = 0.04722177875016895\n",
            "Epoch 5050: b = -0.2462708055973053, w = 0.3902178108692169, loss = 0.04713258197873181\n",
            "Epoch 5100: b = -0.24830138683319092, w = 0.3906654417514801, loss = 0.04704606638961625\n",
            "Epoch 5150: b = -0.2503012418746948, w = 0.39110633730888367, loss = 0.0469621501840877\n",
            "Epoch 5200: b = -0.2522708773612976, w = 0.39154052734375, loss = 0.04688075376523306\n",
            "Epoch 5250: b = -0.2542106807231903, w = 0.39196816086769104, loss = 0.04680180370542795\n",
            "Epoch 5300: b = -0.25612103939056396, w = 0.39238935708999634, loss = 0.04672522850519919\n",
            "Epoch 5350: b = -0.25800251960754395, w = 0.3928040862083435, loss = 0.04665095414591496\n",
            "Epoch 5400: b = -0.2598554790019989, w = 0.39321255683898926, loss = 0.046578912926130214\n",
            "Epoch 5450: b = -0.26168039441108704, w = 0.39361488819122314, loss = 0.04650903672386077\n",
            "Epoch 5500: b = -0.2634776532649994, w = 0.39401108026504517, loss = 0.046441260422502524\n",
            "Epoch 5550: b = -0.2652477025985718, w = 0.39440128207206726, loss = 0.046375521566888254\n",
            "Epoch 5600: b = -0.26699098944664, w = 0.3947855830192566, loss = 0.046311756689801385\n",
            "Epoch 5650: b = -0.26870787143707275, w = 0.3951640725135803, loss = 0.04624990915484049\n",
            "Epoch 5700: b = -0.27039870619773865, w = 0.3955368399620056, loss = 0.04618992072920065\n",
            "Epoch 5750: b = -0.2720640003681183, w = 0.39590397477149963, loss = 0.04613173397053016\n",
            "Epoch 5800: b = -0.273703932762146, w = 0.3962654769420624, loss = 0.04607530076908894\n",
            "Epoch 5850: b = -0.27531906962394714, w = 0.3966215252876282, loss = 0.04602056293664172\n",
            "Epoch 5900: b = -0.27690988779067993, w = 0.39697226881980896, loss = 0.045967465156053176\n",
            "Epoch 5950: b = -0.2784765660762787, w = 0.3973176181316376, loss = 0.045915964937545\n",
            "Epoch 6000: b = -0.2800195515155792, w = 0.3976578116416931, loss = 0.04586601105886397\n",
            "Epoch 6050: b = -0.28153911232948303, w = 0.39799273014068604, loss = 0.04581756073917246\n",
            "Epoch 6100: b = -0.2830356955528259, w = 0.3983226716518402, loss = 0.04577056582287976\n",
            "Epoch 6150: b = -0.2845096290111542, w = 0.39864763617515564, loss = 0.045724982424291676\n",
            "Epoch 6200: b = -0.28596121072769165, w = 0.39896759390830994, loss = 0.045680770486161835\n",
            "Epoch 6250: b = -0.2873908281326294, w = 0.3992827534675598, loss = 0.045637886340235315\n",
            "Epoch 6300: b = -0.28879880905151367, w = 0.39959317445755005, loss = 0.04559629115545632\n",
            "Epoch 6350: b = -0.29018548130989075, w = 0.399898886680603, loss = 0.045555945630206235\n",
            "Epoch 6400: b = -0.2915511429309845, w = 0.4001999795436859, loss = 0.045516812779590875\n",
            "Epoch 6450: b = -0.2928961515426636, w = 0.4004964530467987, loss = 0.045478855335522476\n",
            "Epoch 6500: b = -0.29422080516815186, w = 0.40078848600387573, loss = 0.045442038264049495\n",
            "Epoch 6550: b = -0.29552537202835083, w = 0.401076078414917, loss = 0.04540632899032628\n",
            "Epoch 6600: b = -0.29681020975112915, w = 0.40135931968688965, loss = 0.0453716921090217\n",
            "Epoch 6650: b = -0.2980755567550659, w = 0.4016382396221161, loss = 0.045338097129577815\n",
            "Epoch 6700: b = -0.2993217408657074, w = 0.4019129276275635, loss = 0.045305511770739736\n",
            "Epoch 6750: b = -0.300549179315567, w = 0.40218353271484375, loss = 0.0452739028640607\n",
            "Epoch 6800: b = -0.3017580211162567, w = 0.4024500548839569, loss = 0.045243243292716465\n",
            "Epoch 6850: b = -0.3029484450817108, w = 0.40271246433258057, loss = 0.04521350900417776\n",
            "Epoch 6900: b = -0.30412086844444275, w = 0.40297091007232666, loss = 0.045184667422359964\n",
            "Epoch 6950: b = -0.3052755296230316, w = 0.40322551131248474, loss = 0.04515669252783569\n",
            "Epoch 7000: b = -0.3064126968383789, w = 0.40347614884376526, loss = 0.045129558881676995\n",
            "Epoch 7050: b = -0.3075326383113861, w = 0.4037230908870697, loss = 0.04510324089762664\n",
            "Epoch 7100: b = -0.3086356520652771, w = 0.40396618843078613, loss = 0.04507771373214182\n",
            "Epoch 7150: b = -0.3097219467163086, w = 0.4042057394981384, loss = 0.045052953370624746\n",
            "Epoch 7200: b = -0.3107917904853821, w = 0.4044415056705475, loss = 0.04502893768752314\n",
            "Epoch 7250: b = -0.31184542179107666, w = 0.40467381477355957, loss = 0.04500564353437775\n",
            "Epoch 7300: b = -0.3128831088542938, w = 0.4049025774002075, loss = 0.0449830491400346\n",
            "Epoch 7350: b = -0.31390511989593506, w = 0.4051278531551361, loss = 0.04496113378260783\n",
            "Epoch 7400: b = -0.3149116337299347, w = 0.4053497612476349, loss = 0.04493987662048553\n",
            "Epoch 7450: b = -0.3159029185771942, w = 0.40556833148002625, loss = 0.04491925848108808\n",
            "Epoch 7500: b = -0.3168790936470032, w = 0.4057835042476654, loss = 0.044899262087388765\n",
            "Epoch 7550: b = -0.3178406059741974, w = 0.4059954285621643, loss = 0.04487986436283434\n",
            "Epoch 7600: b = -0.318787544965744, w = 0.4062041938304901, loss = 0.04486105014864153\n",
            "Epoch 7650: b = -0.31972014904022217, w = 0.40640977025032043, loss = 0.04484280078505189\n",
            "Epoch 7700: b = -0.32063862681388855, w = 0.40661224722862244, loss = 0.04482510038070768\n",
            "Epoch 7750: b = -0.3215431869029999, w = 0.4068116843700409, loss = 0.04480793193973831\n",
            "Epoch 7800: b = -0.32243403792381287, w = 0.4070080518722534, loss = 0.04479127928075874\n",
            "Epoch 7850: b = -0.32331138849258423, w = 0.40720146894454956, loss = 0.04477512764099519\n",
            "Epoch 7900: b = -0.32417547702789307, w = 0.4073919653892517, loss = 0.04475946142714369\n",
            "Epoch 7950: b = -0.3250264823436737, w = 0.40757954120635986, loss = 0.04474426558691252\n",
            "Epoch 8000: b = -0.3258645832538605, w = 0.4077643156051636, loss = 0.04472952653127433\n",
            "Epoch 8050: b = -0.32669001817703247, w = 0.40794628858566284, loss = 0.04471523046587705\n",
            "Epoch 8100: b = -0.32750287652015686, w = 0.40812551975250244, loss = 0.044701364712565646\n",
            "Epoch 8150: b = -0.3283034861087799, w = 0.40830203890800476, loss = 0.04468791522064309\n",
            "Epoch 8200: b = -0.32909196615219116, w = 0.4084758162498474, loss = 0.04467487011149075\n",
            "Epoch 8250: b = -0.32986852526664734, w = 0.40864697098731995, loss = 0.044662216677320586\n",
            "Epoch 8300: b = -0.33063334226608276, w = 0.4088156223297119, loss = 0.044649942917329974\n",
            "Epoch 8350: b = -0.331386536359787, w = 0.40898171067237854, loss = 0.044638039180778064\n",
            "Epoch 8400: b = -0.3321283161640167, w = 0.40914514660835266, loss = 0.04462649318493404\n",
            "Epoch 8450: b = -0.33285894989967346, w = 0.40930625796318054, loss = 0.04461529282638746\n",
            "Epoch 8500: b = -0.3335784375667572, w = 0.40946489572525024, loss = 0.04460442999850242\n",
            "Epoch 8550: b = -0.33428704738616943, w = 0.4096210300922394, loss = 0.04459389398772872\n",
            "Epoch 8600: b = -0.3349849581718445, w = 0.4097749888896942, loss = 0.04458367356274444\n",
            "Epoch 8650: b = -0.3356722891330719, w = 0.4099264144897461, loss = 0.04457376112002878\n",
            "Epoch 8700: b = -0.3363491892814636, w = 0.41007569432258606, loss = 0.04456414631883151\n",
            "Epoch 8750: b = -0.33701586723327637, w = 0.4102226197719574, loss = 0.044554820427751954\n",
            "Epoch 8800: b = -0.33767247200012207, w = 0.4103674292564392, loss = 0.044545774087286404\n",
            "Epoch 8850: b = -0.3383190929889679, w = 0.4105099141597748, loss = 0.04453700095962871\n",
            "Epoch 8900: b = -0.33895593881607056, w = 0.41065043210983276, loss = 0.0445284903380706\n",
            "Epoch 8950: b = -0.339583158493042, w = 0.41078856587409973, loss = 0.04452023623811515\n",
            "Epoch 9000: b = -0.34020084142684937, w = 0.4109247922897339, loss = 0.044512229861098575\n",
            "Epoch 9050: b = -0.340809166431427, w = 0.41105887293815613, loss = 0.04450446462565762\n",
            "Epoch 9100: b = -0.34140828251838684, w = 0.4111908972263336, loss = 0.04449693283853584\n",
            "Epoch 9150: b = -0.3419983685016632, w = 0.41132107377052307, loss = 0.04448962648520824\n",
            "Epoch 9200: b = -0.34257951378822327, w = 0.4114491641521454, loss = 0.04448253996672042\n",
            "Epoch 9250: b = -0.34315183758735657, w = 0.4115752577781677, loss = 0.04447566685562928\n",
            "Epoch 9300: b = -0.34371551871299744, w = 0.4116995632648468, loss = 0.044468999705678386\n",
            "Epoch 9350: b = -0.34427064657211304, w = 0.41182205080986023, loss = 0.04446253326883305\n",
            "Epoch 9400: b = -0.3448173701763153, w = 0.4119424819946289, loss = 0.04445626121428785\n",
            "Epoch 9450: b = -0.3453558385372162, w = 0.4120611250400543, loss = 0.04445017767902346\n",
            "Epoch 9500: b = -0.34588611125946045, w = 0.41217803955078125, loss = 0.0444442769182131\n",
            "Epoch 9550: b = -0.3464083671569824, w = 0.4122932255268097, loss = 0.04443855354632857\n",
            "Epoch 9600: b = -0.34692275524139404, w = 0.41240671277046204, loss = 0.044433001640838604\n",
            "Epoch 9650: b = -0.3474293351173401, w = 0.41251832246780396, loss = 0.04442761675125088\n",
            "Epoch 9700: b = -0.3479282259941101, w = 0.41262826323509216, loss = 0.044422394165029064\n",
            "Epoch 9750: b = -0.34841951727867126, w = 0.41273653507232666, loss = 0.04441732895858183\n",
            "Epoch 9800: b = -0.34890344738960266, w = 0.4128431975841522, loss = 0.04441241513139358\n",
            "Epoch 9850: b = -0.3493800163269043, w = 0.41294825077056885, loss = 0.04440764926474751\n",
            "Epoch 9900: b = -0.3498493731021881, w = 0.4130517244338989, loss = 0.04440302681988037\n",
            "Epoch 9950: b = -0.3503115773200989, w = 0.41315361857414246, loss = 0.044398543441413925\n",
            "Epoch 10000: b = -0.3507668375968933, w = 0.4132539927959442, loss = 0.04439419423274981\n",
            "Epoch 10050: b = -0.3512152135372162, w = 0.4133528172969818, loss = 0.04438997595317114\n",
            "Epoch 10100: b = -0.3516567349433899, w = 0.4134501814842224, loss = 0.04438588466724113\n",
            "Epoch 10150: b = -0.35209164023399353, w = 0.41354602575302124, loss = 0.04438191605600959\n",
            "Epoch 10200: b = -0.3525198996067047, w = 0.41364043951034546, loss = 0.044378066918423865\n",
            "Epoch 10250: b = -0.35294169187545776, w = 0.41373342275619507, loss = 0.04437433353838864\n",
            "Epoch 10300: b = -0.35335713624954224, w = 0.41382497549057007, loss = 0.044370712056443586\n",
            "Epoch 10350: b = -0.3537663221359253, w = 0.4139151871204376, loss = 0.04436719905143065\n",
            "Epoch 10400: b = -0.35416924953460693, w = 0.41400402784347534, loss = 0.044363791882339\n",
            "Epoch 10450: b = -0.3545660674571991, w = 0.414091557264328, loss = 0.04436048733159058\n",
            "Epoch 10500: b = -0.3549569249153137, w = 0.4141777753829956, loss = 0.0443572816764631\n",
            "Epoch 10550: b = -0.3553418219089508, w = 0.41426271200180054, loss = 0.04435417268046818\n",
            "Epoch 10600: b = -0.3557209074497223, w = 0.4143461585044861, loss = 0.044351157491450244\n",
            "Epoch 10650: b = -0.35609421133995056, w = 0.4144284129142761, loss = 0.04434823286922589\n",
            "Epoch 10700: b = -0.35646185278892517, w = 0.4145094156265259, loss = 0.044345396201487926\n",
            "Epoch 10750: b = -0.35682395100593567, w = 0.4145892560482025, loss = 0.044342644490182645\n",
            "Epoch 10800: b = -0.357180655002594, w = 0.4146679639816284, loss = 0.04433997492209252\n",
            "Epoch 10850: b = -0.3575318455696106, w = 0.4147454500198364, loss = 0.044337386243746606\n",
            "Epoch 10900: b = -0.35787779092788696, w = 0.414821594953537, loss = 0.044334875056219115\n",
            "Epoch 10950: b = -0.3582184612751007, w = 0.4148966372013092, loss = 0.04433243969804908\n",
            "Epoch 11000: b = -0.35855400562286377, w = 0.41497066617012024, loss = 0.04433007691732857\n",
            "Epoch 11050: b = -0.35888439416885376, w = 0.4150436818599701, loss = 0.04432778571004275\n",
            "Epoch 11100: b = -0.3592098355293274, w = 0.41511523723602295, loss = 0.04432556345031296\n",
            "Epoch 11150: b = -0.35953035950660706, w = 0.4151858389377594, loss = 0.04432340752094839\n",
            "Epoch 11200: b = -0.35984596610069275, w = 0.4152555465698242, loss = 0.0443213167160536\n",
            "Epoch 11250: b = -0.3601568341255188, w = 0.4153240919113159, loss = 0.04431928866892689\n",
            "Epoch 11300: b = -0.3604629933834076, w = 0.4153914451599121, loss = 0.04431732173490062\n",
            "Epoch 11350: b = -0.3607645332813263, w = 0.41545799374580383, loss = 0.04431541351313115\n",
            "Epoch 11400: b = -0.3610614836215973, w = 0.41552355885505676, loss = 0.04431356277623437\n",
            "Epoch 11450: b = -0.36135393381118774, w = 0.415587842464447, loss = 0.044311768002603454\n",
            "Epoch 11500: b = -0.3616419732570648, w = 0.41565144062042236, loss = 0.044310026685498986\n",
            "Epoch 11550: b = -0.3619256019592285, w = 0.4157140254974365, loss = 0.04430833806800779\n",
            "Epoch 11600: b = -0.36220499873161316, w = 0.41577544808387756, loss = 0.044306700062945806\n",
            "Epoch 11650: b = -0.36248019337654114, w = 0.41583630442619324, loss = 0.04430511067612607\n",
            "Epoch 11700: b = -0.36275118589401245, w = 0.41589590907096863, loss = 0.044303569669283394\n",
            "Epoch 11750: b = -0.3630180358886719, w = 0.41595470905303955, loss = 0.0443020751776907\n",
            "Epoch 11800: b = -0.3632808327674866, w = 0.41601282358169556, loss = 0.04430062529385242\n",
            "Epoch 11850: b = -0.36353975534439087, w = 0.4160696864128113, loss = 0.044299218822567814\n",
            "Epoch 11900: b = -0.3637946844100952, w = 0.4161261022090912, loss = 0.04429785466699196\n",
            "Epoch 11950: b = -0.36404576897621155, w = 0.4161812663078308, loss = 0.04429653174654115\n",
            "Epoch 12000: b = -0.36429309844970703, w = 0.41623586416244507, loss = 0.04429524816291176\n",
            "Epoch 12050: b = -0.3645365536212921, w = 0.4162895381450653, loss = 0.04429400376751484\n",
            "Epoch 12100: b = -0.36477646231651306, w = 0.4163423776626587, loss = 0.044292796222091105\n",
            "Epoch 12150: b = -0.36501264572143555, w = 0.41639453172683716, loss = 0.04429162516819387\n",
            "Epoch 12200: b = -0.3652452826499939, w = 0.41644570231437683, loss = 0.04429048946618837\n",
            "Epoch 12250: b = -0.3654744327068329, w = 0.4164963662624359, loss = 0.04428938748213552\n",
            "Epoch 12300: b = -0.3657000660896301, w = 0.41654592752456665, loss = 0.04428831899262116\n",
            "Epoch 12350: b = -0.3659222424030304, w = 0.41659510135650635, loss = 0.04428728258676898\n",
            "Epoch 12400: b = -0.366141140460968, w = 0.4166431725025177, loss = 0.04428627726218873\n",
            "Epoch 12450: b = -0.3663567006587982, w = 0.416690856218338, loss = 0.044285301947140726\n",
            "Epoch 12500: b = -0.36656901240348816, w = 0.41673749685287476, loss = 0.044284356019747055\n",
            "Epoch 12550: b = -0.36677804589271545, w = 0.4167836904525757, loss = 0.044283438687674495\n",
            "Epoch 12600: b = -0.36698397994041443, w = 0.41682904958724976, loss = 0.044282548742634\n",
            "Epoch 12650: b = -0.3671867251396179, w = 0.4168737530708313, loss = 0.04428168582008683\n",
            "Epoch 12700: b = -0.36738649010658264, w = 0.4169178307056427, loss = 0.04428084839430915\n",
            "Epoch 12750: b = -0.36758315563201904, w = 0.41696107387542725, loss = 0.04428003659417216\n",
            "Epoch 12800: b = -0.36777690052986145, w = 0.4170039892196655, loss = 0.0442792486562996\n",
            "Epoch 12850: b = -0.3679676651954651, w = 0.41704580187797546, loss = 0.04427848497794553\n",
            "Epoch 12900: b = -0.3681555688381195, w = 0.41708752512931824, loss = 0.04427774368706925\n",
            "Epoch 12950: b = -0.3683406710624695, w = 0.4171280860900879, loss = 0.04427702491898762\n",
            "Epoch 13000: b = -0.36852291226387024, w = 0.4171683192253113, loss = 0.044276327750733896\n",
            "Epoch 13050: b = -0.3687024712562561, w = 0.4172079563140869, loss = 0.0442756513256994\n",
            "Epoch 13100: b = -0.36887916922569275, w = 0.4172467291355133, loss = 0.0442749958515023\n",
            "Epoch 13150: b = -0.3690532147884369, w = 0.4172854423522949, loss = 0.044274359556793895\n",
            "Epoch 13200: b = -0.3692247271537781, w = 0.41732296347618103, loss = 0.044273742511862856\n",
            "Epoch 13250: b = -0.36939361691474915, w = 0.41736021637916565, loss = 0.04427314386814151\n",
            "Epoch 13300: b = -0.3695599138736725, w = 0.41739705204963684, loss = 0.04427256331961062\n",
            "Epoch 13350: b = -0.3697236478328705, w = 0.41743290424346924, loss = 0.04427200054985134\n",
            "Epoch 13400: b = -0.36988499760627747, w = 0.4174686670303345, loss = 0.044271454076121194\n",
            "Epoch 13450: b = -0.3700438439846039, w = 0.4175036549568176, loss = 0.04427092445154878\n",
            "Epoch 13500: b = -0.3702002465724945, w = 0.41753795742988586, loss = 0.044270410893161145\n",
            "Epoch 13550: b = -0.3703543543815613, w = 0.4175722301006317, loss = 0.04426991229232278\n",
            "Epoch 13600: b = -0.3705061376094818, w = 0.41760551929473877, loss = 0.044269428849205664\n",
            "Epoch 13650: b = -0.3706556558609009, w = 0.41763836145401, loss = 0.04426895990211567\n",
            "Epoch 13700: b = -0.37080273032188416, w = 0.4176711440086365, loss = 0.04426850519918745\n",
            "Epoch 13750: b = -0.37094783782958984, w = 0.41770291328430176, loss = 0.04426806382191477\n",
            "Epoch 13800: b = -0.37109044194221497, w = 0.41773420572280884, loss = 0.044267636472185616\n",
            "Epoch 13850: b = -0.3712310791015625, w = 0.4177654981613159, loss = 0.044267221222454384\n",
            "Epoch 13900: b = -0.3713696002960205, w = 0.41779592633247375, loss = 0.04426681855291292\n",
            "Epoch 13950: b = -0.3715059459209442, w = 0.4178258180618286, loss = 0.04426642833756689\n",
            "Epoch 14000: b = -0.3716403543949127, w = 0.4178556203842163, loss = 0.044266049206837986\n",
            "Epoch 14050: b = -0.3717725872993469, w = 0.41788482666015625, loss = 0.04426568198588439\n",
            "Epoch 14100: b = -0.3719028830528259, w = 0.4179133176803589, loss = 0.04426532580128854\n",
            "Epoch 14150: b = -0.37203118205070496, w = 0.4179416298866272, loss = 0.04426498015711018\n",
            "Epoch 14200: b = -0.3721575140953064, w = 0.41796979308128357, loss = 0.0442646448599302\n",
            "Epoch 14250: b = -0.3722819983959198, w = 0.41799700260162354, loss = 0.04426431978102212\n",
            "Epoch 14300: b = -0.3724046051502228, w = 0.41802388429641724, loss = 0.044264004405082824\n",
            "Epoch 14350: b = -0.37252527475357056, w = 0.41805070638656616, loss = 0.044263698439094945\n",
            "Epoch 14400: b = -0.3726441562175751, w = 0.4180769920349121, loss = 0.044263401696742005\n",
            "Epoch 14450: b = -0.37276121973991394, w = 0.41810259222984314, loss = 0.04426311407473709\n",
            "Epoch 14500: b = -0.37287649512290955, w = 0.41812795400619507, loss = 0.044262835050775155\n",
            "Epoch 14550: b = -0.37299007177352905, w = 0.4181532859802246, loss = 0.044262564123601474\n",
            "Epoch 14600: b = -0.373102068901062, w = 0.41817790269851685, loss = 0.044262301175626816\n",
            "Epoch 14650: b = -0.37321215867996216, w = 0.4182019829750061, loss = 0.04426204662347197\n",
            "Epoch 14700: b = -0.3733205199241638, w = 0.41822582483291626, loss = 0.04426179985109746\n",
            "Epoch 14750: b = -0.3734273314476013, w = 0.4182496666908264, loss = 0.04426156012294823\n",
            "Epoch 14800: b = -0.37353262305259705, w = 0.41827285289764404, loss = 0.044261327517343484\n",
            "Epoch 14850: b = -0.37363624572753906, w = 0.4182955026626587, loss = 0.04426110215334703\n",
            "Epoch 14900: b = -0.37373825907707214, w = 0.41831791400909424, loss = 0.04426088359254132\n",
            "Epoch 14950: b = -0.37383872270584106, w = 0.418340265750885, loss = 0.04426067147985537\n",
            "Epoch 15000: b = -0.37393781542778015, w = 0.41836225986480713, loss = 0.04426046545253743\n",
            "Epoch 15050: b = -0.3740353584289551, w = 0.41838356852531433, loss = 0.044260265851813564\n",
            "Epoch 15100: b = -0.37413135170936584, w = 0.41840457916259766, loss = 0.04426007238895609\n",
            "Epoch 15150: b = -0.37422582507133484, w = 0.41842544078826904, loss = 0.04425988478904226\n",
            "Epoch 15200: b = -0.3743189573287964, w = 0.41844630241394043, loss = 0.04425970252669807\n",
            "Epoch 15250: b = -0.3744107782840729, w = 0.4184664487838745, loss = 0.04425952571061286\n",
            "Epoch 15300: b = -0.37450113892555237, w = 0.41848620772361755, loss = 0.044259354378638496\n",
            "Epoch 15350: b = -0.37459006905555725, w = 0.4185056984424591, loss = 0.04425918829146633\n",
            "Epoch 15400: b = -0.3746776878833771, w = 0.4185250699520111, loss = 0.0442590270611805\n",
            "Epoch 15450: b = -0.3747641146183014, w = 0.4185444414615631, loss = 0.04425887038306806\n",
            "Epoch 15500: b = -0.3748491108417511, w = 0.4185630977153778, loss = 0.04425871871901857\n",
            "Epoch 15550: b = -0.37493279576301575, w = 0.41858139634132385, loss = 0.044258571689822716\n",
            "Epoch 15600: b = -0.37501516938209534, w = 0.418599396944046, loss = 0.04425842915670818\n",
            "Epoch 15650: b = -0.37509626150131226, w = 0.418617308139801, loss = 0.044258290890993986\n",
            "Epoch 15700: b = -0.37517625093460083, w = 0.41863518953323364, loss = 0.04425815649165819\n",
            "Epoch 15750: b = -0.3752552270889282, w = 0.4186526834964752, loss = 0.044258025899822424\n",
            "Epoch 15800: b = -0.37533271312713623, w = 0.4186696410179138, loss = 0.044257899756757244\n",
            "Epoch 15850: b = -0.37540900707244873, w = 0.41868630051612854, loss = 0.04425777742354945\n",
            "Epoch 15900: b = -0.3754841685295105, w = 0.4187028110027313, loss = 0.04425765870368636\n",
            "Epoch 15950: b = -0.3755582869052887, w = 0.41871920228004456, loss = 0.044257543364715594\n",
            "Epoch 16000: b = -0.37563130259513855, w = 0.4187355935573578, loss = 0.04425743142595848\n",
            "Epoch 16050: b = -0.3757031559944153, w = 0.41875144839286804, loss = 0.04425732298226015\n",
            "Epoch 16100: b = -0.37577399611473083, w = 0.41876691579818726, loss = 0.04425721772721817\n",
            "Epoch 16150: b = -0.3758438229560852, w = 0.41878217458724976, loss = 0.044257115554252456\n",
            "Epoch 16200: b = -0.3759123682975769, w = 0.41879716515541077, loss = 0.044257016810430275\n",
            "Epoch 16250: b = -0.37597978115081787, w = 0.418812096118927, loss = 0.04425692106548696\n",
            "Epoch 16300: b = -0.37604647874832153, w = 0.41882699728012085, loss = 0.04425682773060817\n",
            "Epoch 16350: b = -0.37611204385757446, w = 0.4188416302204132, loss = 0.04425673740588662\n",
            "Epoch 16400: b = -0.3761766254901886, w = 0.418855756521225, loss = 0.04425664983318969\n",
            "Epoch 16450: b = -0.37624040246009827, w = 0.4188697040081024, loss = 0.04425656466211909\n",
            "Epoch 16500: b = -0.3763029873371124, w = 0.41888338327407837, loss = 0.044256482387207426\n",
            "Epoch 16550: b = -0.37636449933052063, w = 0.41889688372612, loss = 0.04425640269115456\n",
            "Epoch 16600: b = -0.3764253854751587, w = 0.41891029477119446, loss = 0.04425632498512291\n",
            "Epoch 16650: b = -0.3764849901199341, w = 0.4189237058162689, loss = 0.04425625002322367\n",
            "Epoch 16700: b = -0.37654414772987366, w = 0.41893690824508667, loss = 0.04425617673683023\n",
            "Epoch 16750: b = -0.37660226225852966, w = 0.41894960403442383, loss = 0.044256105945507454\n",
            "Epoch 16800: b = -0.3766593635082245, w = 0.4189620912075043, loss = 0.04425603740339234\n",
            "Epoch 16850: b = -0.37671592831611633, w = 0.41897445917129517, loss = 0.044255970534501476\n",
            "Epoch 16900: b = -0.37677106261253357, w = 0.4189865291118622, loss = 0.04425590637067664\n",
            "Epoch 16950: b = -0.3768256902694702, w = 0.4189985394477844, loss = 0.044255843710090496\n",
            "Epoch 17000: b = -0.37687933444976807, w = 0.4190104603767395, loss = 0.04425578310753558\n",
            "Epoch 17050: b = -0.3769323527812958, w = 0.4190223813056946, loss = 0.04425572405368228\n",
            "Epoch 17100: b = -0.37698450684547424, w = 0.4190340042114258, loss = 0.04425566689768289\n",
            "Epoch 17150: b = -0.3770360052585602, w = 0.41904526948928833, loss = 0.04425561133152072\n",
            "Epoch 17200: b = -0.37708666920661926, w = 0.41905632615089417, loss = 0.04425555752295182\n",
            "Epoch 17250: b = -0.3771364390850067, w = 0.4190672039985657, loss = 0.04425550543662285\n",
            "Epoch 17300: b = -0.3771856129169464, w = 0.41907796263694763, loss = 0.04425545477918045\n",
            "Epoch 17350: b = -0.37723374366760254, w = 0.4190884828567505, loss = 0.044255405918866245\n",
            "Epoch 17400: b = -0.37728142738342285, w = 0.4190989136695862, loss = 0.04425535826979279\n",
            "Epoch 17450: b = -0.3773280084133148, w = 0.4191093444824219, loss = 0.0442553123443789\n",
            "Epoch 17500: b = -0.37737420201301575, w = 0.41911977529525757, loss = 0.044255267498569215\n",
            "Epoch 17550: b = -0.37741994857788086, w = 0.41912999749183655, loss = 0.0442552237511555\n",
            "Epoch 17600: b = -0.3774646520614624, w = 0.4191397726535797, loss = 0.04425518172266809\n",
            "Epoch 17650: b = -0.37750905752182007, w = 0.4191494882106781, loss = 0.04425514057987458\n",
            "Epoch 17700: b = -0.3775522708892822, w = 0.419158935546875, loss = 0.044255101174269805\n",
            "Epoch 17750: b = -0.3775954246520996, w = 0.4191683828830719, loss = 0.04425506239690994\n",
            "Epoch 17800: b = -0.3776371479034424, w = 0.41917750239372253, loss = 0.04425502549335683\n",
            "Epoch 17850: b = -0.37767887115478516, w = 0.4191865921020508, loss = 0.044254989146511554\n",
            "Epoch 17900: b = -0.3777194023132324, w = 0.41919559240341187, loss = 0.04425495432005646\n",
            "Epoch 17950: b = -0.3777596354484558, w = 0.4192045331001282, loss = 0.044254920293068475\n",
            "Epoch 18000: b = -0.37779948115348816, w = 0.4192134737968445, loss = 0.04425488706599923\n",
            "Epoch 18050: b = -0.37783822417259216, w = 0.41922226548194885, loss = 0.0442548552539281\n",
            "Epoch 18100: b = -0.37787696719169617, w = 0.41923072934150696, loss = 0.04425482397759388\n",
            "Epoch 18150: b = -0.3779148459434509, w = 0.41923901438713074, loss = 0.04425479383895256\n",
            "Epoch 18200: b = -0.37795209884643555, w = 0.4192471504211426, loss = 0.04425476466533775\n",
            "Epoch 18250: b = -0.3779892325401306, w = 0.4192552864551544, loss = 0.04425473601050416\n",
            "Epoch 18300: b = -0.37802499532699585, w = 0.41926309466362, loss = 0.044254708846595915\n",
            "Epoch 18350: b = -0.3780607581138611, w = 0.41927090287208557, loss = 0.04425468209657342\n",
            "Epoch 18400: b = -0.3780958354473114, w = 0.4192785918712616, loss = 0.04425465623088924\n",
            "Epoch 18450: b = -0.37813010811805725, w = 0.4192860722541809, loss = 0.044254631364437434\n",
            "Epoch 18500: b = -0.3781643807888031, w = 0.4192935526371002, loss = 0.04425460687362458\n",
            "Epoch 18550: b = -0.3781975507736206, w = 0.41930103302001953, loss = 0.04425458347023748\n",
            "Epoch 18600: b = -0.37823033332824707, w = 0.41930848360061646, loss = 0.04425456069916001\n",
            "Epoch 18650: b = -0.37826311588287354, w = 0.4193159341812134, loss = 0.04425453827464791\n",
            "Epoch 18700: b = -0.3782954514026642, w = 0.41932302713394165, loss = 0.04425451650574135\n",
            "Epoch 18750: b = -0.37832674384117126, w = 0.4193298816680908, loss = 0.04425449578530257\n",
            "Epoch 18800: b = -0.37835803627967834, w = 0.4193367063999176, loss = 0.04425447537401697\n",
            "Epoch 18850: b = -0.3783888518810272, w = 0.4193434417247772, loss = 0.04425445556364309\n",
            "Epoch 18900: b = -0.3784186542034149, w = 0.4193499684333801, loss = 0.04425443670962936\n",
            "Epoch 18950: b = -0.3784484565258026, w = 0.41935646533966064, loss = 0.04425441814363569\n",
            "Epoch 19000: b = -0.37847796082496643, w = 0.4193629324436188, loss = 0.04425440002111222\n",
            "Epoch 19050: b = -0.37850627303123474, w = 0.4193691313266754, loss = 0.044254382914311045\n",
            "Epoch 19100: b = -0.37853458523750305, w = 0.41937530040740967, loss = 0.04425436605985904\n",
            "Epoch 19150: b = -0.37856289744377136, w = 0.4193814992904663, loss = 0.04425434946175292\n",
            "Epoch 19200: b = -0.3785898983478546, w = 0.41938748955726624, loss = 0.0442543338446513\n",
            "Epoch 19250: b = -0.37861672043800354, w = 0.4193934500217438, loss = 0.04425431857718922\n",
            "Epoch 19300: b = -0.37864354252815247, w = 0.4193994104862213, loss = 0.04425430354013839\n",
            "Epoch 19350: b = -0.37867024540901184, w = 0.41940537095069885, loss = 0.04425428878009266\n",
            "Epoch 19400: b = -0.3786955773830414, w = 0.4194113314151764, loss = 0.044254274970433424\n",
            "Epoch 19450: b = -0.3787209093570709, w = 0.4194168448448181, loss = 0.044254261412739165\n",
            "Epoch 19500: b = -0.37874624133110046, w = 0.4194223880767822, loss = 0.04425424806337514\n",
            "Epoch 19550: b = -0.37877157330513, w = 0.41942793130874634, loss = 0.04425423491610694\n",
            "Epoch 19600: b = -0.37879547476768494, w = 0.4194331467151642, loss = 0.0442542226834295\n",
            "Epoch 19650: b = -0.3788193166255951, w = 0.41943836212158203, loss = 0.044254210679644274\n",
            "Epoch 19700: b = -0.37884315848350525, w = 0.4194435775279999, loss = 0.04425419885764205\n",
            "Epoch 19750: b = -0.37886691093444824, w = 0.41944876313209534, loss = 0.04425418724803965\n",
            "Epoch 19800: b = -0.378889262676239, w = 0.4194536507129669, loss = 0.04425417650019518\n",
            "Epoch 19850: b = -0.3789116144180298, w = 0.4194585382938385, loss = 0.04425416591212044\n",
            "Epoch 19900: b = -0.37893396615982056, w = 0.4194634258747101, loss = 0.044254155483815456\n",
            "Epoch 19950: b = -0.37895631790161133, w = 0.41946831345558167, loss = 0.04425414521528017\n",
            "Epoch 20000: b = -0.37897735834121704, w = 0.41947293281555176, loss = 0.04425413568052363\n",
            "Epoch 20050: b = -0.3789982199668884, w = 0.4194774925708771, loss = 0.04425412638148049\n",
            "Epoch 20100: b = -0.3790190815925598, w = 0.4194820523262024, loss = 0.04425411722470853\n",
            "Epoch 20150: b = -0.3790399432182312, w = 0.4194866120815277, loss = 0.04425410820401862\n",
            "Epoch 20200: b = -0.37906017899513245, w = 0.41949111223220825, loss = 0.04425409956402923\n",
            "Epoch 20250: b = -0.37907955050468445, w = 0.4194955825805664, loss = 0.0442540914150165\n",
            "Epoch 20300: b = -0.37909892201423645, w = 0.41950005292892456, loss = 0.044254083387982875\n",
            "Epoch 20350: b = -0.37911829352378845, w = 0.4195045232772827, loss = 0.04425407548292834\n",
            "Epoch 20400: b = -0.37913766503334045, w = 0.41950878500938416, loss = 0.044254067714685666\n",
            "Epoch 20450: b = -0.37915703654289246, w = 0.4195130169391632, loss = 0.044254060068690045\n",
            "Epoch 20500: b = -0.3791755437850952, w = 0.41951707005500793, loss = 0.044254052864161585\n",
            "Epoch 20550: b = -0.37919342517852783, w = 0.4195209741592407, loss = 0.044254046019005684\n",
            "Epoch 20600: b = -0.37921130657196045, w = 0.4195248782634735, loss = 0.04425403927610271\n",
            "Epoch 20650: b = -0.37922918796539307, w = 0.4195287823677063, loss = 0.04425403263545267\n",
            "Epoch 20700: b = -0.3792470693588257, w = 0.4195326864719391, loss = 0.04425402609482793\n",
            "Epoch 20750: b = -0.3792644143104553, w = 0.4195365011692047, loss = 0.04425401984027003\n",
            "Epoch 20800: b = -0.37928080558776855, w = 0.41954007744789124, loss = 0.04425401402782509\n",
            "Epoch 20850: b = -0.3792971968650818, w = 0.41954365372657776, loss = 0.04425400829908037\n",
            "Epoch 20900: b = -0.379313588142395, w = 0.4195472300052643, loss = 0.04425400265847261\n",
            "Epoch 20950: b = -0.37932997941970825, w = 0.4195508062839508, loss = 0.04425399710378653\n",
            "Epoch 21000: b = -0.3793463706970215, w = 0.4195544123649597, loss = 0.04425399163502212\n",
            "Epoch 21050: b = -0.3793617784976959, w = 0.4195577800273895, loss = 0.04425398656083438\n",
            "Epoch 21100: b = -0.37937667965888977, w = 0.4195610284805298, loss = 0.04425398173755158\n",
            "Epoch 21150: b = -0.3793915808200836, w = 0.41956427693367004, loss = 0.044253976985279705\n",
            "Epoch 21200: b = -0.37940648198127747, w = 0.4195675551891327, loss = 0.044253972304018736\n",
            "Epoch 21250: b = -0.3794213831424713, w = 0.41957080364227295, loss = 0.04425396769155121\n",
            "Epoch 21300: b = -0.37943628430366516, w = 0.4195740520954132, loss = 0.04425396315230366\n",
            "Epoch 21350: b = -0.37945061922073364, w = 0.4195772111415863, loss = 0.044253958841654874\n",
            "Epoch 21400: b = -0.3794640302658081, w = 0.4195801913738251, loss = 0.04425395487453032\n",
            "Epoch 21450: b = -0.37947744131088257, w = 0.41958317160606384, loss = 0.04425395096500858\n",
            "Epoch 21500: b = -0.37949085235595703, w = 0.4195861518383026, loss = 0.044253947113089644\n",
            "Epoch 21550: b = -0.3795042634010315, w = 0.4195891320705414, loss = 0.044253943318773525\n",
            "Epoch 21600: b = -0.37951767444610596, w = 0.41959211230278015, loss = 0.04425393958206022\n",
            "Epoch 21650: b = -0.3795310854911804, w = 0.4195950925350189, loss = 0.044253935902949716\n",
            "Epoch 21700: b = -0.3795444965362549, w = 0.4195980727672577, loss = 0.04425393228144203\n",
            "Epoch 21750: b = -0.3795567750930786, w = 0.41960105299949646, loss = 0.04425392899482024\n",
            "Epoch 21800: b = -0.3795686960220337, w = 0.4196038246154785, loss = 0.044253925865624696\n",
            "Epoch 21850: b = -0.37958061695098877, w = 0.41960641741752625, loss = 0.044253922789107995\n",
            "Epoch 21900: b = -0.37959253787994385, w = 0.41960904002189636, loss = 0.04425391975937474\n",
            "Epoch 21950: b = -0.3796044588088989, w = 0.4196116328239441, loss = 0.044253916773752164\n",
            "Epoch 22000: b = -0.379616379737854, w = 0.4196142554283142, loss = 0.04425391383490778\n",
            "Epoch 22050: b = -0.3796283006668091, w = 0.41961684823036194, loss = 0.044253910941514346\n",
            "Epoch 22100: b = -0.37964022159576416, w = 0.41961947083473206, loss = 0.04425390809222385\n",
            "Epoch 22150: b = -0.37965208292007446, w = 0.4196220636367798, loss = 0.044253905296376995\n",
            "Epoch 22200: b = -0.37966251373291016, w = 0.41962432861328125, loss = 0.04425390288019838\n",
            "Epoch 22250: b = -0.37967294454574585, w = 0.4196266233921051, loss = 0.044253900500144376\n",
            "Epoch 22300: b = -0.37968337535858154, w = 0.41962888836860657, loss = 0.044253898153554565\n",
            "Epoch 22350: b = -0.37969380617141724, w = 0.4196311831474304, loss = 0.04425389584308871\n",
            "Epoch 22400: b = -0.37970423698425293, w = 0.4196334481239319, loss = 0.04425389356608774\n",
            "Epoch 22450: b = -0.3797146677970886, w = 0.41963574290275574, loss = 0.044253891325209994\n",
            "Epoch 22500: b = -0.3797250986099243, w = 0.4196380078792572, loss = 0.04425388911779786\n",
            "Epoch 22550: b = -0.37973552942276, w = 0.41964030265808105, loss = 0.04425388694650823\n",
            "Epoch 22600: b = -0.37974581122398376, w = 0.41964253783226013, loss = 0.0442538848330792\n",
            "Epoch 22650: b = -0.3797547519207001, w = 0.4196445047855377, loss = 0.04425388302934218\n",
            "Epoch 22700: b = -0.3797636926174164, w = 0.4196464419364929, loss = 0.04425388124983492\n",
            "Epoch 22750: b = -0.3797726333141327, w = 0.4196484088897705, loss = 0.04425387949589676\n",
            "Epoch 22800: b = -0.379781574010849, w = 0.4196503460407257, loss = 0.044253877768843555\n",
            "Epoch 22850: b = -0.3797905147075653, w = 0.4196523129940033, loss = 0.04425387606602994\n",
            "Epoch 22900: b = -0.3797994554042816, w = 0.4196542799472809, loss = 0.04425387439010513\n",
            "Epoch 22950: b = -0.3798083961009979, w = 0.4196562170982361, loss = 0.04425387273841603\n",
            "Epoch 23000: b = -0.37981733679771423, w = 0.41965818405151367, loss = 0.0442538711136196\n",
            "Epoch 23050: b = -0.37982627749443054, w = 0.41966012120246887, loss = 0.04425386951305505\n",
            "Epoch 23100: b = -0.37983521819114685, w = 0.41966208815574646, loss = 0.04425386793805959\n",
            "Epoch 23150: b = -0.37984320521354675, w = 0.41966384649276733, loss = 0.044253866547790496\n",
            "Epoch 23200: b = -0.3798506557941437, w = 0.41966545581817627, loss = 0.04425386527523937\n",
            "Epoch 23250: b = -0.3798581063747406, w = 0.4196670949459076, loss = 0.04425386401912378\n",
            "Epoch 23300: b = -0.3798655569553375, w = 0.4196687340736389, loss = 0.04425386278208235\n",
            "Epoch 23350: b = -0.37987300753593445, w = 0.41967034339904785, loss = 0.044253861561468016\n",
            "Epoch 23400: b = -0.37988045811653137, w = 0.4196719825267792, loss = 0.044253860358609995\n",
            "Epoch 23450: b = -0.3798879086971283, w = 0.4196735918521881, loss = 0.04425385917482313\n",
            "Epoch 23500: b = -0.3798953592777252, w = 0.41967523097991943, loss = 0.04425385800746636\n",
            "Epoch 23550: b = -0.37990280985832214, w = 0.41967687010765076, loss = 0.04425385685786592\n",
            "Epoch 23600: b = -0.37991026043891907, w = 0.4196784794330597, loss = 0.04425385572733366\n",
            "Epoch 23650: b = -0.379917711019516, w = 0.419680118560791, loss = 0.04425385461323447\n",
            "Epoch 23700: b = -0.3799251616001129, w = 0.41968175768852234, loss = 0.044253853516891595\n",
            "Epoch 23750: b = -0.3799324631690979, w = 0.4196833670139313, loss = 0.04425385245557809\n",
            "Epoch 23800: b = -0.37993842363357544, w = 0.41968485713005066, loss = 0.04425385159809911\n",
            "Epoch 23850: b = -0.379944384098053, w = 0.41968634724617004, loss = 0.04425385075321856\n",
            "Epoch 23900: b = -0.3799503445625305, w = 0.41968783736228943, loss = 0.044253849920936464\n",
            "Epoch 23950: b = -0.37995630502700806, w = 0.4196893274784088, loss = 0.0442538491012528\n",
            "Epoch 24000: b = -0.3799622654914856, w = 0.41969066858291626, loss = 0.04425384829612895\n",
            "Epoch 24050: b = -0.37996822595596313, w = 0.4196919798851013, loss = 0.0442538475028643\n",
            "Epoch 24100: b = -0.3799741864204407, w = 0.4196932911872864, loss = 0.04425384672096369\n",
            "Epoch 24150: b = -0.3799801468849182, w = 0.41969457268714905, loss = 0.044253845950427126\n",
            "Epoch 24200: b = -0.37998610734939575, w = 0.4196958839893341, loss = 0.04425384519170413\n",
            "Epoch 24250: b = -0.3799920678138733, w = 0.41969719529151917, loss = 0.04425384444388654\n",
            "Epoch 24300: b = -0.37999802827835083, w = 0.4196985065937042, loss = 0.04425384370743301\n",
            "Epoch 24350: b = -0.38000398874282837, w = 0.4196997880935669, loss = 0.04425384298279688\n",
            "Epoch 24400: b = -0.3800099492073059, w = 0.41970109939575195, loss = 0.04425384226906231\n",
            "Epoch 24450: b = -0.38001590967178345, w = 0.419702410697937, loss = 0.04425384156669179\n",
            "Epoch 24500: b = -0.380021870136261, w = 0.4197036921977997, loss = 0.044253840875685325\n",
            "Epoch 24550: b = -0.3800278306007385, w = 0.41970500349998474, loss = 0.044253840196491014\n",
            "Epoch 24600: b = -0.38003379106521606, w = 0.4197063148021698, loss = 0.04425383952820352\n",
            "Epoch 24650: b = -0.3800397515296936, w = 0.41970762610435486, loss = 0.044253838871280066\n",
            "Epoch 24700: b = -0.38004547357559204, w = 0.41970887780189514, loss = 0.044253838248327515\n",
            "Epoch 24750: b = -0.3800499439239502, w = 0.41970986127853394, loss = 0.044253837771314156\n",
            "Epoch 24800: b = -0.38005441427230835, w = 0.41971081495285034, loss = 0.044253837300693086\n",
            "Epoch 24850: b = -0.3800588846206665, w = 0.41971179842948914, loss = 0.044253836836910435\n",
            "Epoch 24900: b = -0.38006335496902466, w = 0.41971278190612793, loss = 0.04425383637906707\n",
            "Epoch 24950: b = -0.3800678253173828, w = 0.4197137653827667, loss = 0.04425383592761599\n",
            "Epoch 25000: b = -0.38007229566574097, w = 0.41971471905708313, loss = 0.04425383548255719\n",
            "Epoch 25050: b = -0.3800767660140991, w = 0.4197157025337219, loss = 0.04425383504389065\n",
            "Epoch 25100: b = -0.3800812363624573, w = 0.4197166860103607, loss = 0.04425383461205956\n",
            "Epoch 25150: b = -0.38008570671081543, w = 0.4197176694869995, loss = 0.044253834186170744\n",
            "Epoch 25200: b = -0.3800901770591736, w = 0.4197186529636383, loss = 0.044253833766674196\n",
            "Epoch 25250: b = -0.38009464740753174, w = 0.4197196066379547, loss = 0.04425383335356992\n",
            "Epoch 25300: b = -0.3800991177558899, w = 0.4197205901145935, loss = 0.04425383294730498\n",
            "Epoch 25350: b = -0.38010358810424805, w = 0.4197215735912323, loss = 0.044253832546978414\n",
            "Epoch 25400: b = -0.3801080584526062, w = 0.4197225570678711, loss = 0.04425383215304414\n",
            "Epoch 25450: b = -0.38011252880096436, w = 0.4197235107421875, loss = 0.04425383176550214\n",
            "Epoch 25500: b = -0.3801169991493225, w = 0.4197244942188263, loss = 0.04425383138435242\n",
            "Epoch 25550: b = -0.38012146949768066, w = 0.4197254776954651, loss = 0.044253831010039026\n",
            "Epoch 25600: b = -0.3801259398460388, w = 0.4197264611721039, loss = 0.04425383064166701\n",
            "Epoch 25650: b = -0.380130410194397, w = 0.4197274446487427, loss = 0.04425383027968728\n",
            "Epoch 25700: b = -0.3801348805427551, w = 0.4197283983230591, loss = 0.044253829924099805\n",
            "Epoch 25750: b = -0.38013893365859985, w = 0.4197292923927307, loss = 0.04425382960497613\n",
            "Epoch 25800: b = -0.3801419138908386, w = 0.41972994804382324, loss = 0.04425382937536064\n",
            "Epoch 25850: b = -0.3801448941230774, w = 0.41973060369491577, loss = 0.04425382914858616\n",
            "Epoch 25900: b = -0.38014787435531616, w = 0.4197312593460083, loss = 0.044253828925091894\n",
            "Epoch 25950: b = -0.38015085458755493, w = 0.41973191499710083, loss = 0.04425382870399488\n",
            "Epoch 26000: b = -0.3801538348197937, w = 0.41973257064819336, loss = 0.04425382848573887\n",
            "Epoch 26050: b = -0.38015681505203247, w = 0.4197331964969635, loss = 0.04425382827032388\n",
            "Epoch 26100: b = -0.38015979528427124, w = 0.41973385214805603, loss = 0.04425382805774989\n",
            "Epoch 26150: b = -0.38016277551651, w = 0.41973450779914856, loss = 0.044253827848016916\n",
            "Epoch 26200: b = -0.3801657557487488, w = 0.4197351634502411, loss = 0.04425382764112496\n",
            "Epoch 26250: b = -0.38016873598098755, w = 0.4197358191013336, loss = 0.04425382743751252\n",
            "Epoch 26300: b = -0.3801717162132263, w = 0.41973647475242615, loss = 0.04425382723629802\n",
            "Epoch 26350: b = -0.3801746964454651, w = 0.4197371304035187, loss = 0.04425382703792454\n",
            "Epoch 26400: b = -0.38017767667770386, w = 0.4197377562522888, loss = 0.04425382684239206\n",
            "Epoch 26450: b = -0.3801806569099426, w = 0.41973841190338135, loss = 0.04425382664970061\n",
            "Epoch 26500: b = -0.3801836371421814, w = 0.4197390675544739, loss = 0.04425382645985016\n",
            "Epoch 26550: b = -0.38018661737442017, w = 0.4197397232055664, loss = 0.04425382627284071\n",
            "Epoch 26600: b = -0.38018959760665894, w = 0.41974037885665894, loss = 0.044253826089110104\n",
            "Epoch 26650: b = -0.3801925778388977, w = 0.41974103450775146, loss = 0.044253825907778134\n",
            "Epoch 26700: b = -0.3801955580711365, w = 0.419741690158844, loss = 0.04425382572928716\n",
            "Epoch 26750: b = -0.38019853830337524, w = 0.41974231600761414, loss = 0.044253825553637216\n",
            "Epoch 26800: b = -0.380201518535614, w = 0.41974297165870667, loss = 0.04425382538082827\n",
            "Epoch 26850: b = -0.3802044987678528, w = 0.4197436273097992, loss = 0.04425382521086036\n",
            "Epoch 26900: b = -0.38020747900009155, w = 0.4197442829608917, loss = 0.044253825044175105\n",
            "Epoch 26950: b = -0.3802104592323303, w = 0.41974493861198425, loss = 0.04425382487988465\n",
            "Epoch 27000: b = -0.3802134394645691, w = 0.4197455942630768, loss = 0.0442538247184352\n",
            "Epoch 27050: b = -0.38021641969680786, w = 0.4197462201118469, loss = 0.04425382455982675\n",
            "Epoch 27100: b = -0.38021939992904663, w = 0.41974687576293945, loss = 0.04425382440405932\n",
            "Epoch 27150: b = -0.3802223801612854, w = 0.419747531414032, loss = 0.044253824251132896\n",
            "Epoch 27200: b = -0.38022536039352417, w = 0.4197481870651245, loss = 0.0442538241010475\n",
            "Epoch 27250: b = -0.38022834062576294, w = 0.41974884271621704, loss = 0.044253823954244084\n",
            "Epoch 27300: b = -0.38023126125335693, w = 0.41974949836730957, loss = 0.04425382381116746\n",
            "Epoch 27350: b = -0.38023290038108826, w = 0.4197498559951782, loss = 0.044253823732983415\n",
            "Epoch 27400: b = -0.38023439049720764, w = 0.4197501540184021, loss = 0.04425382366261217\n",
            "Epoch 27450: b = -0.380235880613327, w = 0.41975048184394836, loss = 0.04425382359295119\n",
            "Epoch 27500: b = -0.3802373707294464, w = 0.41975080966949463, loss = 0.04425382352400044\n",
            "Epoch 27550: b = -0.3802388608455658, w = 0.4197511374950409, loss = 0.04425382345575997\n",
            "Epoch 27600: b = -0.3802403509616852, w = 0.41975146532058716, loss = 0.044253823388229724\n",
            "Epoch 27650: b = -0.38024184107780457, w = 0.4197517931461334, loss = 0.04425382332140974\n",
            "Epoch 27700: b = -0.38024333119392395, w = 0.4197521209716797, loss = 0.04425382325530003\n",
            "Epoch 27750: b = -0.38024482131004333, w = 0.41975244879722595, loss = 0.044253823189900544\n",
            "Epoch 27800: b = -0.3802463114261627, w = 0.4197527766227722, loss = 0.044253823125211325\n",
            "Epoch 27850: b = -0.3802478015422821, w = 0.4197531044483185, loss = 0.044253823061232364\n",
            "Epoch 27900: b = -0.3802492916584015, w = 0.41975343227386475, loss = 0.04425382299796364\n",
            "Epoch 27950: b = -0.3802507817745209, w = 0.419753760099411, loss = 0.044253822935839245\n",
            "Epoch 28000: b = -0.38025227189064026, w = 0.4197540879249573, loss = 0.044253822873988775\n",
            "Epoch 28050: b = -0.38025376200675964, w = 0.41975441575050354, loss = 0.04425382281284852\n",
            "Epoch 28100: b = -0.38025525212287903, w = 0.4197547137737274, loss = 0.04425382275241854\n",
            "Epoch 28150: b = -0.3802567422389984, w = 0.4197550415992737, loss = 0.04425382269269881\n",
            "Epoch 28200: b = -0.3802582323551178, w = 0.41975536942481995, loss = 0.04425382263368933\n",
            "Epoch 28250: b = -0.3802597224712372, w = 0.4197556972503662, loss = 0.04425382257539012\n",
            "Epoch 28300: b = -0.38026121258735657, w = 0.4197560250759125, loss = 0.04425382251780114\n",
            "Epoch 28350: b = -0.38026270270347595, w = 0.41975635290145874, loss = 0.04425382246092242\n",
            "Epoch 28400: b = -0.38026419281959534, w = 0.419756680727005, loss = 0.04425382240475395\n",
            "Epoch 28450: b = -0.3802656829357147, w = 0.41975700855255127, loss = 0.04425382234929573\n",
            "Epoch 28500: b = -0.3802671730518341, w = 0.41975733637809753, loss = 0.04425382229454778\n",
            "Epoch 28550: b = -0.3802686631679535, w = 0.4197576642036438, loss = 0.04425382224051007\n",
            "Epoch 28600: b = -0.3802701532840729, w = 0.41975799202919006, loss = 0.04425382218718262\n",
            "Epoch 28650: b = -0.38027164340019226, w = 0.41975831985473633, loss = 0.044253822134998795\n",
            "Epoch 28700: b = -0.38027313351631165, w = 0.4197586476802826, loss = 0.04425382208308957\n",
            "Epoch 28750: b = -0.38027462363243103, w = 0.41975897550582886, loss = 0.04425382203189058\n",
            "Epoch 28800: b = -0.3802761137485504, w = 0.41975927352905273, loss = 0.04425382198140187\n",
            "Epoch 28850: b = -0.3802776038646698, w = 0.419759601354599, loss = 0.044253821931623395\n",
            "Epoch 28900: b = -0.3802790939807892, w = 0.41975992918014526, loss = 0.04425382188255518\n",
            "Epoch 28950: b = -0.38028058409690857, w = 0.41976025700569153, loss = 0.04425382183419721\n",
            "Epoch 29000: b = -0.38028207421302795, w = 0.4197605848312378, loss = 0.0442538217865495\n",
            "Epoch 29050: b = -0.38028356432914734, w = 0.41976091265678406, loss = 0.04425382173961205\n",
            "Epoch 29100: b = -0.3802850544452667, w = 0.4197612404823303, loss = 0.04425382169338484\n",
            "Epoch 29150: b = -0.3802865445613861, w = 0.4197615683078766, loss = 0.04425382164786789\n",
            "Epoch 29200: b = -0.3802880346775055, w = 0.41976189613342285, loss = 0.04425382160306119\n",
            "Epoch 29250: b = -0.3802895247936249, w = 0.4197622239589691, loss = 0.044253821558964734\n",
            "Epoch 29300: b = -0.38029101490974426, w = 0.4197625517845154, loss = 0.04425382151601351\n",
            "Epoch 29350: b = -0.38029250502586365, w = 0.41976287961006165, loss = 0.04425382147333531\n",
            "Epoch 29400: b = -0.38029399514198303, w = 0.4197632074356079, loss = 0.04425382143136733\n",
            "Epoch 29450: b = -0.3802954852581024, w = 0.4197635054588318, loss = 0.04425382139010961\n",
            "Epoch 29500: b = -0.3802969753742218, w = 0.41976383328437805, loss = 0.04425382134956215\n",
            "Epoch 29550: b = -0.3802984654903412, w = 0.4197641611099243, loss = 0.044253821309724925\n",
            "Epoch 29600: b = -0.38029995560646057, w = 0.4197644889354706, loss = 0.04425382127059799\n",
            "Epoch 29650: b = -0.38030144572257996, w = 0.41976481676101685, loss = 0.04425382123218127\n",
            "Epoch 29700: b = -0.38030293583869934, w = 0.4197651445865631, loss = 0.04425382119447483\n",
            "Epoch 29750: b = -0.3803044259548187, w = 0.4197654724121094, loss = 0.04425382115747863\n",
            "Epoch 29800: b = -0.3803059160709381, w = 0.41976580023765564, loss = 0.04425382112119268\n",
            "Epoch 29850: b = -0.3803074061870575, w = 0.4197661280632019, loss = 0.04425382108561701\n",
            "Epoch 29900: b = -0.3803088963031769, w = 0.41976645588874817, loss = 0.04425382105075156\n",
            "Epoch 29950: b = -0.38031038641929626, w = 0.41976678371429443, loss = 0.044253821016596376\n",
            "Epoch 30000: b = -0.38031187653541565, w = 0.4197671115398407, loss = 0.04425382098358572\n",
            "Epoch 30050: b = -0.38031336665153503, w = 0.41976743936538696, loss = 0.04425382095084875\n",
            "Epoch 30100: b = -0.3803148567676544, w = 0.4197677671909332, loss = 0.04425382091882204\n",
            "Epoch 30150: b = -0.3803163468837738, w = 0.4197680652141571, loss = 0.044253820887505596\n",
            "Epoch 30200: b = -0.3803178369998932, w = 0.41976839303970337, loss = 0.04425382085689938\n",
            "Epoch 30250: b = -0.3803193271160126, w = 0.41976872086524963, loss = 0.04425382082700344\n",
            "Epoch 30300: b = -0.38032081723213196, w = 0.4197690486907959, loss = 0.04425382079781775\n",
            "Epoch 30350: b = -0.38032230734825134, w = 0.41976937651634216, loss = 0.04425382076934229\n",
            "Epoch 30400: b = -0.3803237974643707, w = 0.4197697043418884, loss = 0.04425382074157712\n",
            "Epoch 30450: b = -0.3803246319293976, w = 0.41976988315582275, loss = 0.04425382072596452\n",
            "Epoch 30500: b = -0.3803246319293976, w = 0.41976988315582275, loss = 0.04425382072596452\n",
            "Epoch 30550: b = -0.3803246319293976, w = 0.41976988315582275, loss = 0.04425382072596452\n",
            "Epoch 30600: b = -0.3803246319293976, w = 0.41976988315582275, loss = 0.04425382072596452\n",
            "Epoch 30650: b = -0.3803246319293976, w = 0.41976988315582275, loss = 0.04425382072596452\n",
            "Epoch 30700: b = -0.3803246319293976, w = 0.41976988315582275, loss = 0.04425382072596452\n",
            "Epoch 30750: b = -0.3803246319293976, w = 0.41976988315582275, loss = 0.04425382072596452\n",
            "Epoch 30800: b = -0.3803246319293976, w = 0.41976988315582275, loss = 0.04425382072596452\n",
            "Epoch 30850: b = -0.3803246319293976, w = 0.41976988315582275, loss = 0.04425382072596452\n",
            "Epoch 30900: b = -0.3803246319293976, w = 0.41976988315582275, loss = 0.04425382072596452\n",
            "Epoch 30950: b = -0.3803246319293976, w = 0.41976988315582275, loss = 0.04425382072596452\n",
            "Epoch 31000: b = -0.3803246319293976, w = 0.41976988315582275, loss = 0.04425382072596452\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Batch"
      ],
      "metadata": {
        "id": "e9NtAIHuunye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define la tasa de aprendizaje\n",
        "lr = 0.001\n",
        "\n",
        "# Número de épocas\n",
        "n_epochs = 20000\n",
        "\n",
        "# Tamaño del mini-batch\n",
        "batch_size = 32\n",
        "\n",
        "# Inicialización de parámetros\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float32)\n",
        "w = torch.randn(1, requires_grad=True, dtype=torch.float32)\n",
        "\n",
        "# Bucle de entrenamiento\n",
        "for epoch in range(n_epochs):\n",
        "    # Mezclar los datos en cada época (opcional pero recomendado)\n",
        "    indices = torch.randperm(len(x_train_tensor))\n",
        "    x_train_tensor = x_train_tensor[indices]\n",
        "    y_train_tensor = y_train_tensor[indices]\n",
        "\n",
        "    # Iterar sobre mini-lotes\n",
        "    for i in range(0, len(x_train_tensor), batch_size):\n",
        "        # Seleccionar el mini-batch actual\n",
        "        x_batch = x_train_tensor[i:i + batch_size]\n",
        "        y_batch = y_train_tensor[i:i + batch_size]\n",
        "\n",
        "        # Paso 1: Predicción del modelo\n",
        "        yhat = b + w * x_batch\n",
        "\n",
        "        # Paso 2: Cálculo de la pérdida (error cuadrático medio para el mini-batch)\n",
        "        loss = ((yhat - y_batch) ** 2).mean()\n",
        "\n",
        "        # Paso 3: Cálculo de gradientes\n",
        "        loss.backward()\n",
        "\n",
        "        # Paso 4: Actualización de parámetros\n",
        "        with torch.no_grad():\n",
        "            b -= lr * b.grad\n",
        "            w -= lr * w.grad\n",
        "\n",
        "        # Limpiar gradientes antes de la siguiente iteración\n",
        "        b.grad.zero_()\n",
        "        w.grad.zero_()\n",
        "\n",
        "    # Imprimir cada 50 épocas o en épocas específicas\n",
        "    if (epoch + 1) in [1, 10, 30] or (epoch + 1) % 50 == 0:\n",
        "        print(f\"Época {epoch+1}: b = {b.item()}, w = {w.item()}, pérdida = {loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8aqKN6Iumru",
        "outputId": "d2b5b9f7-ba21-473c-d3e0-3e9333e4384a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Época 1: b = -1.099576711654663, w = -0.08388510346412659, pérdida = 8.526732789194492\n",
            "Época 10: b = -0.9899784922599792, w = 0.38290342688560486, pérdida = 0.6549741116400277\n",
            "Época 30: b = -0.9420388340950012, w = 0.534775972366333, pérdida = 0.06709950405212052\n",
            "Época 50: b = -0.9267549514770508, w = 0.5401038527488708, pérdida = 0.07022358863318233\n",
            "Época 100: b = -0.8943546414375305, w = 0.5332629680633545, pérdida = 0.06210325433472904\n",
            "Época 150: b = -0.8638348579406738, w = 0.5264601707458496, pérdida = 0.06983461061741576\n",
            "Época 200: b = -0.8352720141410828, w = 0.5201169848442078, pérdida = 0.04551444432427321\n",
            "Época 250: b = -0.8083080649375916, w = 0.5140758752822876, pérdida = 0.09311152718669487\n",
            "Época 300: b = -0.7828769683837891, w = 0.5087029337882996, pérdida = 0.09916774763571824\n",
            "Época 350: b = -0.7591798305511475, w = 0.5033190846443176, pérdida = 0.07749742687256321\n",
            "Época 400: b = -0.7366461753845215, w = 0.49828040599823, pérdida = 0.06282728057357174\n",
            "Época 450: b = -0.7155811786651611, w = 0.4933618903160095, pérdida = 0.0414073020422587\n",
            "Época 500: b = -0.6956024169921875, w = 0.4895183742046356, pérdida = 0.08333475865819417\n",
            "Época 550: b = -0.677041232585907, w = 0.48510128259658813, pérdida = 0.08630820978974484\n",
            "Época 600: b = -0.6594159603118896, w = 0.48168548941612244, pérdida = 0.06137909124623703\n",
            "Época 650: b = -0.6429255604743958, w = 0.47765594720840454, pérdida = 0.05059827930386238\n",
            "Época 700: b = -0.6274005174636841, w = 0.4743819534778595, pérdida = 0.05835076714661883\n",
            "Época 750: b = -0.6127964854240417, w = 0.4711008667945862, pérdida = 0.04125583213351094\n",
            "Época 800: b = -0.5989982485771179, w = 0.4681798219680786, pérdida = 0.042877593157371635\n",
            "Época 850: b = -0.5860813856124878, w = 0.4654035270214081, pérdida = 0.0440787161970372\n",
            "Época 900: b = -0.5738694667816162, w = 0.4626808762550354, pérdida = 0.03364720251563925\n",
            "Época 950: b = -0.5624048709869385, w = 0.46028003096580505, pérdida = 0.06116679886908897\n",
            "Época 1000: b = -0.5516075491905212, w = 0.4579642117023468, pérdida = 0.04954719243798919\n",
            "Época 1050: b = -0.541511595249176, w = 0.4554855525493622, pérdida = 0.0751129059090175\n",
            "Época 1100: b = -0.5321136116981506, w = 0.4528917074203491, pérdida = 0.04706614781062979\n",
            "Época 1150: b = -0.5230244398117065, w = 0.4514623284339905, pérdida = 0.07879933501340551\n",
            "Época 1200: b = -0.5145800113677979, w = 0.4494985044002533, pérdida = 0.036670948149364356\n",
            "Época 1250: b = -0.5066311955451965, w = 0.4476664364337921, pérdida = 0.05168092485674991\n",
            "Época 1300: b = -0.49905842542648315, w = 0.4462718963623047, pérdida = 0.03361008955729036\n",
            "Época 1350: b = -0.4921232759952545, w = 0.44448915123939514, pérdida = 0.06330850945618403\n",
            "Época 1400: b = -0.4855280816555023, w = 0.44273725152015686, pérdida = 0.033368347213515955\n",
            "Época 1450: b = -0.47916510701179504, w = 0.44190478324890137, pérdida = 0.041499500103335064\n",
            "Época 1500: b = -0.4733754098415375, w = 0.44010642170906067, pérdida = 0.07167889751231327\n",
            "Época 1550: b = -0.46786928176879883, w = 0.43878498673439026, pérdida = 0.060087396245187163\n",
            "Época 1600: b = -0.4626327455043793, w = 0.43786653876304626, pérdida = 0.05086914582544599\n",
            "Época 1650: b = -0.45772358775138855, w = 0.43679487705230713, pérdida = 0.0433200041482372\n",
            "Época 1700: b = -0.45307108759880066, w = 0.43589186668395996, pérdida = 0.031044624796847647\n",
            "Época 1750: b = -0.44867536425590515, w = 0.4351750314235687, pérdida = 0.04173444854705186\n",
            "Época 1800: b = -0.444685161113739, w = 0.43394094705581665, pérdida = 0.04267156092149768\n",
            "Época 1850: b = -0.4409281015396118, w = 0.43284663558006287, pérdida = 0.03462925290063962\n",
            "Época 1900: b = -0.43735945224761963, w = 0.43221554160118103, pérdida = 0.034958469416421466\n",
            "Época 1950: b = -0.4339720606803894, w = 0.43180179595947266, pérdida = 0.0552207904207907\n",
            "Época 2000: b = -0.43080541491508484, w = 0.4308345913887024, pérdida = 0.04110444591524089\n",
            "Época 2050: b = -0.4277186691761017, w = 0.4303463101387024, pérdida = 0.0325728615009735\n",
            "Época 2100: b = -0.4249833822250366, w = 0.42944037914276123, pérdida = 0.06482325100366322\n",
            "Época 2150: b = -0.422267347574234, w = 0.42911800742149353, pérdida = 0.027751491219786404\n",
            "Época 2200: b = -0.41985824704170227, w = 0.4283972978591919, pérdida = 0.04863412975299355\n",
            "Época 2250: b = -0.41762545704841614, w = 0.42745184898376465, pérdida = 0.04222396551620857\n",
            "Época 2300: b = -0.41535720229148865, w = 0.4274258613586426, pérdida = 0.021331333336447145\n",
            "Época 2350: b = -0.4133025109767914, w = 0.4269673228263855, pérdida = 0.03688194184639314\n",
            "Época 2400: b = -0.41139352321624756, w = 0.4265379309654236, pérdida = 0.03323631241217611\n",
            "Época 2450: b = -0.4094773828983307, w = 0.4264778792858124, pérdida = 0.06171339281394401\n",
            "Época 2500: b = -0.4078100025653839, w = 0.42560362815856934, pérdida = 0.0540973872753339\n",
            "Época 2550: b = -0.4062114953994751, w = 0.42513829469680786, pérdida = 0.047453298660159494\n",
            "Época 2600: b = -0.4045524299144745, w = 0.42532879114151, pérdida = 0.048812003383692674\n",
            "Época 2650: b = -0.40320444107055664, w = 0.424593061208725, pérdida = 0.03674386440140329\n",
            "Época 2700: b = -0.4018178880214691, w = 0.4244309663772583, pérdida = 0.06281764828237829\n",
            "Época 2750: b = -0.40059694647789, w = 0.4239348769187927, pérdida = 0.04957100129325995\n",
            "Época 2800: b = -0.39933621883392334, w = 0.42382705211639404, pérdida = 0.05488806455981462\n",
            "Época 2850: b = -0.39823323488235474, w = 0.42347288131713867, pérdida = 0.036680373867727704\n",
            "Época 2900: b = -0.3971197307109833, w = 0.4232960045337677, pérdida = 0.06099314401289801\n",
            "Época 2950: b = -0.39605557918548584, w = 0.42349696159362793, pérdida = 0.061225948345631664\n",
            "Época 3000: b = -0.3951977491378784, w = 0.42298179864883423, pérdida = 0.057217120158148144\n",
            "Época 3050: b = -0.39435577392578125, w = 0.4226062595844269, pérdida = 0.02878217094518594\n",
            "Época 3100: b = -0.39339756965637207, w = 0.4228978753089905, pérdida = 0.0418122352730334\n",
            "Época 3150: b = -0.39268335700035095, w = 0.4221673309803009, pérdida = 0.04217631019280854\n",
            "Época 3200: b = -0.3918721079826355, w = 0.4225229024887085, pérdida = 0.029463813644069758\n",
            "Época 3250: b = -0.3912012577056885, w = 0.4226822853088379, pérdida = 0.06468205009037503\n",
            "Época 3300: b = -0.39069634675979614, w = 0.4220132529735565, pérdida = 0.04013764651071799\n",
            "Época 3350: b = -0.3899877071380615, w = 0.42236217856407166, pérdida = 0.037248391355568504\n",
            "Época 3400: b = -0.38954252004623413, w = 0.42171990871429443, pérdida = 0.02789367390377\n",
            "Época 3450: b = -0.388932466506958, w = 0.4219774007797241, pérdida = 0.03775432878478949\n",
            "Época 3500: b = -0.38842350244522095, w = 0.4219386577606201, pérdida = 0.04478099087597683\n",
            "Época 3550: b = -0.3879917562007904, w = 0.4213958978652954, pérdida = 0.035894938054047636\n",
            "Época 3600: b = -0.38745248317718506, w = 0.42167049646377563, pérdida = 0.04671442431458773\n",
            "Época 3650: b = -0.3870328366756439, w = 0.4213278591632843, pérdida = 0.043462250170663665\n",
            "Época 3700: b = -0.3867190480232239, w = 0.42082929611206055, pérdida = 0.05172814114661765\n",
            "Época 3750: b = -0.3862576186656952, w = 0.4210101068019867, pérdida = 0.04726539092227285\n",
            "Época 3800: b = -0.3858049511909485, w = 0.42122316360473633, pérdida = 0.0424038126711292\n",
            "Época 3850: b = -0.3855062425136566, w = 0.4209791421890259, pérdida = 0.03709928252700439\n",
            "Época 3900: b = -0.38514989614486694, w = 0.421299010515213, pérdida = 0.037729536571867235\n",
            "Época 3950: b = -0.3849571943283081, w = 0.4205109179019928, pérdida = 0.026482591838424132\n",
            "Época 4000: b = -0.38447004556655884, w = 0.4213307499885559, pérdida = 0.05801052163286654\n",
            "Época 4050: b = -0.3843831717967987, w = 0.42043256759643555, pérdida = 0.026161711528774334\n",
            "Época 4100: b = -0.38404908776283264, w = 0.4208158850669861, pérdida = 0.04952711900066764\n",
            "Época 4150: b = -0.3839232325553894, w = 0.42044785618782043, pérdida = 0.06881788132517619\n",
            "Época 4200: b = -0.3837307393550873, w = 0.42034053802490234, pérdida = 0.03457303282281268\n",
            "Época 4250: b = -0.3834739029407501, w = 0.4202643930912018, pérdida = 0.036818297049832846\n",
            "Época 4300: b = -0.3832421898841858, w = 0.4204769730567932, pérdida = 0.03252446510142958\n",
            "Época 4350: b = -0.383102685213089, w = 0.42040690779685974, pérdida = 0.044281348365632904\n",
            "Época 4400: b = -0.3829296827316284, w = 0.42028099298477173, pérdida = 0.044519782015696084\n",
            "Época 4450: b = -0.3826729953289032, w = 0.42034465074539185, pérdida = 0.03302833216457058\n",
            "Época 4500: b = -0.3825295865535736, w = 0.420384019613266, pérdida = 0.03241762451622562\n",
            "Época 4550: b = -0.3824106454849243, w = 0.4204108715057373, pérdida = 0.023841417674347953\n",
            "Época 4600: b = -0.3823336362838745, w = 0.4204173982143402, pérdida = 0.05150578432672325\n",
            "Época 4650: b = -0.3822840452194214, w = 0.4201084077358246, pérdida = 0.04539004622415527\n",
            "Época 4700: b = -0.3821132779121399, w = 0.4202863872051239, pérdida = 0.07267818532503333\n",
            "Época 4750: b = -0.3820911645889282, w = 0.420067697763443, pérdida = 0.038163092725030316\n",
            "Época 4800: b = -0.38198044896125793, w = 0.42006024718284607, pérdida = 0.026208570087658246\n",
            "Época 4850: b = -0.38179346919059753, w = 0.42039772868156433, pérdida = 0.049996155470082536\n",
            "Época 4900: b = -0.38188478350639343, w = 0.41961076855659485, pérdida = 0.07408743119736869\n",
            "Época 4950: b = -0.3817737102508545, w = 0.4199994206428528, pérdida = 0.04152931545211384\n",
            "Época 5000: b = -0.38175585865974426, w = 0.41953045129776, pérdida = 0.040880217852647616\n",
            "Época 5050: b = -0.3815513551235199, w = 0.42016229033470154, pérdida = 0.045299756603852104\n",
            "Época 5100: b = -0.38153988122940063, w = 0.4199424386024475, pérdida = 0.031831809804161226\n",
            "Época 5150: b = -0.38146260380744934, w = 0.42003557085990906, pérdida = 0.06738808661526452\n",
            "Época 5200: b = -0.3813174068927765, w = 0.42018836736679077, pérdida = 0.03790326692699445\n",
            "Época 5250: b = -0.38133180141448975, w = 0.4200141429901123, pérdida = 0.02475976534998255\n",
            "Época 5300: b = -0.38130390644073486, w = 0.41990983486175537, pérdida = 0.04527921495759755\n",
            "Época 5350: b = -0.3812236487865448, w = 0.4200464189052582, pérdida = 0.04257982370010697\n",
            "Época 5400: b = -0.38112473487854004, w = 0.42060086131095886, pérdida = 0.05166274361402365\n",
            "Época 5450: b = -0.381130188703537, w = 0.4201384484767914, pérdida = 0.022867687638935\n",
            "Época 5500: b = -0.38118603825569153, w = 0.41979265213012695, pérdida = 0.05079904381506856\n",
            "Época 5550: b = -0.3811209201812744, w = 0.4196818172931671, pérdida = 0.04625245911636688\n",
            "Época 5600: b = -0.38106009364128113, w = 0.4198361337184906, pérdida = 0.0668198978279773\n",
            "Época 5650: b = -0.38097861409187317, w = 0.4198327958583832, pérdida = 0.052662610852127235\n",
            "Época 5700: b = -0.3809452950954437, w = 0.4196896553039551, pérdida = 0.03807301170287616\n",
            "Época 5750: b = -0.380900114774704, w = 0.4197461009025574, pérdida = 0.041298859825718064\n",
            "Época 5800: b = -0.38080933690071106, w = 0.4201010465621948, pérdida = 0.04953393425194805\n",
            "Época 5850: b = -0.380899041891098, w = 0.4198337495326996, pérdida = 0.06650525017961585\n",
            "Época 5900: b = -0.38090401887893677, w = 0.41962897777557373, pérdida = 0.036988886096921525\n",
            "Época 5950: b = -0.38077878952026367, w = 0.4201345145702362, pérdida = 0.02213794777929461\n",
            "Época 6000: b = -0.3807741403579712, w = 0.41983911395072937, pérdida = 0.04003831509908678\n",
            "Época 6050: b = -0.38071179389953613, w = 0.4199654757976532, pérdida = 0.059890183133190854\n",
            "Época 6100: b = -0.3807307481765747, w = 0.41985490918159485, pérdida = 0.047728689796360725\n",
            "Época 6150: b = -0.3807201385498047, w = 0.419807106256485, pérdida = 0.03458186754105679\n",
            "Época 6200: b = -0.3807026445865631, w = 0.4196318984031677, pérdida = 0.04482650299731702\n",
            "Época 6250: b = -0.38059377670288086, w = 0.419944703578949, pérdida = 0.06433952189255766\n",
            "Época 6300: b = -0.38061293959617615, w = 0.4195544421672821, pérdida = 0.03191520391073069\n",
            "Época 6350: b = -0.3805215358734131, w = 0.42009109258651733, pérdida = 0.042010723740463045\n",
            "Época 6400: b = -0.38058754801750183, w = 0.41979655623435974, pérdida = 0.03378469525438707\n",
            "Época 6450: b = -0.38051077723503113, w = 0.419853538274765, pérdida = 0.07222042650286824\n",
            "Época 6500: b = -0.3804783821105957, w = 0.4198940694332123, pérdida = 0.07766708850848593\n",
            "Época 6550: b = -0.3805299997329712, w = 0.41956424713134766, pérdida = 0.033071068915853576\n",
            "Época 6600: b = -0.3805178701877594, w = 0.41999754309654236, pérdida = 0.044051592065493854\n",
            "Época 6650: b = -0.38055339455604553, w = 0.41945138573646545, pérdida = 0.07541048504671398\n",
            "Época 6700: b = -0.38041990995407104, w = 0.4200305640697479, pérdida = 0.04709598739558935\n",
            "Época 6750: b = -0.380498468875885, w = 0.4196624755859375, pérdida = 0.06421436693652814\n",
            "Época 6800: b = -0.3806002140045166, w = 0.4193374216556549, pérdida = 0.031528081368153195\n",
            "Época 6850: b = -0.3804202973842621, w = 0.4199466109275818, pérdida = 0.033380450198743965\n",
            "Época 6900: b = -0.3804780840873718, w = 0.41966742277145386, pérdida = 0.042416895663497954\n",
            "Época 6950: b = -0.3804745376110077, w = 0.41969114542007446, pérdida = 0.051843347312055386\n",
            "Época 7000: b = -0.3804852366447449, w = 0.41980671882629395, pérdida = 0.03896217430735691\n",
            "Época 7050: b = -0.3803037703037262, w = 0.42040690779685974, pérdida = 0.03867081824320476\n",
            "Época 7100: b = -0.38050737977027893, w = 0.41943275928497314, pérdida = 0.057860935310105305\n",
            "Época 7150: b = -0.38044747710227966, w = 0.4193887412548065, pérdida = 0.03681555812003087\n",
            "Época 7200: b = -0.3803892433643341, w = 0.4196597933769226, pérdida = 0.0417176601791601\n",
            "Época 7250: b = -0.3802994191646576, w = 0.4197872579097748, pérdida = 0.06488161912221772\n",
            "Época 7300: b = -0.3803504407405853, w = 0.41948461532592773, pérdida = 0.018493366938977258\n",
            "Época 7350: b = -0.380316823720932, w = 0.41973796486854553, pérdida = 0.025584686677773683\n",
            "Época 7400: b = -0.3803512752056122, w = 0.4192785322666168, pérdida = 0.07718853471950878\n",
            "Época 7450: b = -0.38017696142196655, w = 0.41975003480911255, pérdida = 0.05011276749347746\n",
            "Época 7500: b = -0.3801204264163971, w = 0.42019203305244446, pérdida = 0.028563538754297752\n",
            "Época 7550: b = -0.38022494316101074, w = 0.4197849929332733, pérdida = 0.03993901959210263\n",
            "Época 7600: b = -0.380109041929245, w = 0.42033886909484863, pérdida = 0.04810861482963438\n",
            "Época 7650: b = -0.38026219606399536, w = 0.419731467962265, pérdida = 0.05053634304317844\n",
            "Época 7700: b = -0.3802429735660553, w = 0.4199228286743164, pérdida = 0.03679147714404285\n",
            "Época 7750: b = -0.38029974699020386, w = 0.4198431372642517, pérdida = 0.04946937131819476\n",
            "Época 7800: b = -0.3803097605705261, w = 0.42001673579216003, pérdida = 0.07195339647174621\n",
            "Época 7850: b = -0.3803052008152008, w = 0.4196068048477173, pérdida = 0.061305917976573115\n",
            "Época 7900: b = -0.3802669048309326, w = 0.41987326741218567, pérdida = 0.059007590706715636\n",
            "Época 7950: b = -0.38022685050964355, w = 0.419965535402298, pérdida = 0.04767891564740733\n",
            "Época 8000: b = -0.38037315011024475, w = 0.419404000043869, pérdida = 0.05017503000932899\n",
            "Época 8050: b = -0.3804161250591278, w = 0.4195336401462555, pérdida = 0.04013282699720636\n",
            "Época 8100: b = -0.38039034605026245, w = 0.41997548937797546, pérdida = 0.06620883978791216\n",
            "Época 8150: b = -0.38043493032455444, w = 0.4198533594608307, pérdida = 0.05651395098640132\n",
            "Época 8200: b = -0.3805621266365051, w = 0.4194433391094208, pérdida = 0.05295998926237405\n",
            "Época 8250: b = -0.38035064935684204, w = 0.4201771318912506, pérdida = 0.05787504528166046\n",
            "Época 8300: b = -0.38046693801879883, w = 0.41967806220054626, pérdida = 0.04545133802072938\n",
            "Época 8350: b = -0.38043999671936035, w = 0.41975951194763184, pérdida = 0.03233834854492729\n",
            "Época 8400: b = -0.3804567754268646, w = 0.4198553264141083, pérdida = 0.06082119039489564\n",
            "Época 8450: b = -0.3804359436035156, w = 0.4198933243751526, pérdida = 0.04073605307089453\n",
            "Época 8500: b = -0.3803565502166748, w = 0.4199683666229248, pérdida = 0.04218168295654385\n",
            "Época 8550: b = -0.3803987205028534, w = 0.4199449121952057, pérdida = 0.052889145420305504\n",
            "Época 8600: b = -0.38036981225013733, w = 0.4202162027359009, pérdida = 0.03586608543673062\n",
            "Época 8650: b = -0.38034218549728394, w = 0.41993045806884766, pérdida = 0.034980230712046374\n",
            "Época 8700: b = -0.38037776947021484, w = 0.42013317346572876, pérdida = 0.02677916260481848\n",
            "Época 8750: b = -0.3804861903190613, w = 0.419315367937088, pérdida = 0.06430372639027596\n",
            "Época 8800: b = -0.3803577721118927, w = 0.4199821352958679, pérdida = 0.043178879523537245\n",
            "Época 8850: b = -0.3803822696208954, w = 0.41979050636291504, pérdida = 0.03355257931792041\n",
            "Época 8900: b = -0.38034793734550476, w = 0.41997334361076355, pérdida = 0.042772367234836434\n",
            "Época 8950: b = -0.3804384768009186, w = 0.4198210537433624, pérdida = 0.04439867405940819\n",
            "Época 9000: b = -0.3804047405719757, w = 0.4199845790863037, pérdida = 0.04617554940071572\n",
            "Época 9050: b = -0.38046807050704956, w = 0.41969263553619385, pérdida = 0.02841918748706451\n",
            "Época 9100: b = -0.3803749680519104, w = 0.4197668731212616, pérdida = 0.0464117137399307\n",
            "Época 9150: b = -0.3803560137748718, w = 0.4200747609138489, pérdida = 0.027676206180988275\n",
            "Época 9200: b = -0.3804343044757843, w = 0.4195592701435089, pérdida = 0.04800453477606038\n",
            "Época 9250: b = -0.38040831685066223, w = 0.4195842742919922, pérdida = 0.020123308643840827\n",
            "Época 9300: b = -0.3803742527961731, w = 0.41976213455200195, pérdida = 0.05126070919833581\n",
            "Época 9350: b = -0.3803573548793793, w = 0.41999515891075134, pérdida = 0.04008140769574128\n",
            "Época 9400: b = -0.38048648834228516, w = 0.4196513295173645, pérdida = 0.03573157171434338\n",
            "Época 9450: b = -0.3803980052471161, w = 0.41988813877105713, pérdida = 0.03422452636372158\n",
            "Época 9500: b = -0.3803756535053253, w = 0.41994839906692505, pérdida = 0.047421600698296734\n",
            "Época 9550: b = -0.38040637969970703, w = 0.41994354128837585, pérdida = 0.04252817395880678\n",
            "Época 9600: b = -0.3803957402706146, w = 0.42017754912376404, pérdida = 0.02967662526677256\n",
            "Época 9650: b = -0.3805321455001831, w = 0.41972026228904724, pérdida = 0.01892219264411986\n",
            "Época 9700: b = -0.3804820477962494, w = 0.41977939009666443, pérdida = 0.02969829415670382\n",
            "Época 9750: b = -0.3804875612258911, w = 0.41961291432380676, pérdida = 0.03583294628337222\n",
            "Época 9800: b = -0.38046273589134216, w = 0.41980597376823425, pérdida = 0.04810193141503317\n",
            "Época 9850: b = -0.38044509291648865, w = 0.419771283864975, pérdida = 0.07938587990919065\n",
            "Época 9900: b = -0.3805065155029297, w = 0.41956785321235657, pérdida = 0.04566137264520012\n",
            "Época 9950: b = -0.3804575800895691, w = 0.4195939302444458, pérdida = 0.05172780577814201\n",
            "Época 10000: b = -0.380429208278656, w = 0.4196825921535492, pérdida = 0.02251353687947771\n",
            "Época 10050: b = -0.3803347647190094, w = 0.4200024902820587, pérdida = 0.04008591508984052\n",
            "Época 10100: b = -0.3803413510322571, w = 0.4200249910354614, pérdida = 0.05459076961277617\n",
            "Época 10150: b = -0.38044676184654236, w = 0.4196982979774475, pérdida = 0.029934325610055785\n",
            "Época 10200: b = -0.38036343455314636, w = 0.4199160933494568, pérdida = 0.03516474831970994\n",
            "Época 10250: b = -0.3803429901599884, w = 0.4199627935886383, pérdida = 0.08091337095970785\n",
            "Época 10300: b = -0.38038739562034607, w = 0.4197343587875366, pérdida = 0.03726852700281924\n",
            "Época 10350: b = -0.3804018795490265, w = 0.4199279844760895, pérdida = 0.051863685644842915\n",
            "Época 10400: b = -0.38054338097572327, w = 0.41950348019599915, pérdida = 0.06219771442974692\n",
            "Época 10450: b = -0.380460262298584, w = 0.41970744729042053, pérdida = 0.05430309964648968\n",
            "Época 10500: b = -0.38040488958358765, w = 0.41975662112236023, pérdida = 0.061225241243578914\n",
            "Época 10550: b = -0.38045254349708557, w = 0.41946977376937866, pérdida = 0.07336323159985274\n",
            "Época 10600: b = -0.38035768270492554, w = 0.4199962615966797, pérdida = 0.03788654133482953\n",
            "Época 10650: b = -0.38035523891448975, w = 0.41986364126205444, pérdida = 0.03881070871851202\n",
            "Época 10700: b = -0.38041776418685913, w = 0.4198325574398041, pérdida = 0.033800965877798454\n",
            "Época 10750: b = -0.38048458099365234, w = 0.4194428622722626, pérdida = 0.04476991186621207\n",
            "Época 10800: b = -0.38033658266067505, w = 0.42006418108940125, pérdida = 0.05652298107153486\n",
            "Época 10850: b = -0.3803824782371521, w = 0.4198133647441864, pérdida = 0.06898611110696283\n",
            "Época 10900: b = -0.38041555881500244, w = 0.41964590549468994, pérdida = 0.01871092230225128\n",
            "Época 10950: b = -0.3804033696651459, w = 0.419676274061203, pérdida = 0.04585932188508851\n",
            "Época 11000: b = -0.3804677128791809, w = 0.41949519515037537, pérdida = 0.043793039524949694\n",
            "Época 11050: b = -0.38043075799942017, w = 0.419535368680954, pérdida = 0.06467463182388032\n",
            "Época 11100: b = -0.3804479241371155, w = 0.4196121096611023, pérdida = 0.07513763892674641\n",
            "Época 11150: b = -0.3804374039173126, w = 0.4198160767555237, pérdida = 0.057352504924880456\n",
            "Época 11200: b = -0.38045549392700195, w = 0.4196321666240692, pérdida = 0.05384000717191951\n",
            "Época 11250: b = -0.3805263340473175, w = 0.4193182587623596, pérdida = 0.03933215649212505\n",
            "Época 11300: b = -0.3803967833518982, w = 0.41979333758354187, pérdida = 0.05373852546929398\n",
            "Época 11350: b = -0.3804336488246918, w = 0.4196338653564453, pérdida = 0.04483050747136013\n",
            "Época 11400: b = -0.3804163634777069, w = 0.41927242279052734, pérdida = 0.032389318905163056\n",
            "Época 11450: b = -0.38031506538391113, w = 0.41991081833839417, pérdida = 0.02223501376777343\n",
            "Época 11500: b = -0.3804126977920532, w = 0.4197876751422882, pérdida = 0.01630777592260092\n",
            "Época 11550: b = -0.38046616315841675, w = 0.4197739362716675, pérdida = 0.05338559832904699\n",
            "Época 11600: b = -0.3804436922073364, w = 0.41996973752975464, pérdida = 0.039270920730605036\n",
            "Época 11650: b = -0.3805016875267029, w = 0.4197743237018585, pérdida = 0.03592098973190914\n",
            "Época 11700: b = -0.3805026710033417, w = 0.4197804033756256, pérdida = 0.03736172052441559\n",
            "Época 11750: b = -0.3805474638938904, w = 0.41939759254455566, pérdida = 0.032917392653873216\n",
            "Época 11800: b = -0.380414754152298, w = 0.4199711084365845, pérdida = 0.04387770673883149\n",
            "Época 11850: b = -0.38035500049591064, w = 0.42023175954818726, pérdida = 0.04746901069417514\n",
            "Época 11900: b = -0.3805057406425476, w = 0.4198920428752899, pérdida = 0.037048464278606384\n",
            "Época 11950: b = -0.3805985450744629, w = 0.419475257396698, pérdida = 0.03935975205991034\n",
            "Época 12000: b = -0.3804817199707031, w = 0.41981860995292664, pérdida = 0.037283316567385434\n",
            "Época 12050: b = -0.3805276155471802, w = 0.41974008083343506, pérdida = 0.031123448510604154\n",
            "Época 12100: b = -0.3805452287197113, w = 0.41947728395462036, pérdida = 0.04957709602261229\n",
            "Época 12150: b = -0.38053417205810547, w = 0.41949474811553955, pérdida = 0.02930551289097071\n",
            "Época 12200: b = -0.3804067075252533, w = 0.4201805293560028, pérdida = 0.03389771680209302\n",
            "Época 12250: b = -0.3803834319114685, w = 0.42019331455230713, pérdida = 0.038382678927593374\n",
            "Época 12300: b = -0.3803783357143402, w = 0.4200645983219147, pérdida = 0.03487757003828309\n",
            "Época 12350: b = -0.3804633915424347, w = 0.4196029305458069, pérdida = 0.0321980183020925\n",
            "Época 12400: b = -0.3804653286933899, w = 0.419871062040329, pérdida = 0.029362079998364776\n",
            "Época 12450: b = -0.38050714135169983, w = 0.4196997582912445, pérdida = 0.023698959018144703\n",
            "Época 12500: b = -0.38048699498176575, w = 0.41993439197540283, pérdida = 0.06391875350324212\n",
            "Época 12550: b = -0.38056251406669617, w = 0.4194566011428833, pérdida = 0.06402842285901157\n",
            "Época 12600: b = -0.3804536461830139, w = 0.41974374651908875, pérdida = 0.04179398938050344\n",
            "Época 12650: b = -0.38051366806030273, w = 0.4195950925350189, pérdida = 0.032782723577533195\n",
            "Época 12700: b = -0.38039863109588623, w = 0.419912189245224, pérdida = 0.027735390489356332\n",
            "Época 12750: b = -0.3804396390914917, w = 0.4199410378932953, pérdida = 0.0434905894036691\n",
            "Época 12800: b = -0.3804406523704529, w = 0.4197034537792206, pérdida = 0.061375318301486924\n",
            "Época 12850: b = -0.38042503595352173, w = 0.41990020871162415, pérdida = 0.03156650248175672\n",
            "Época 12900: b = -0.3804212510585785, w = 0.4199000597000122, pérdida = 0.038293544761135105\n",
            "Época 12950: b = -0.3805707097053528, w = 0.4193194806575775, pérdida = 0.02815293995752924\n",
            "Época 13000: b = -0.3805154860019684, w = 0.41935810446739197, pérdida = 0.06536377293273819\n",
            "Época 13050: b = -0.3804375231266022, w = 0.41957521438598633, pérdida = 0.04250561746038992\n",
            "Época 13100: b = -0.3803331255912781, w = 0.41989973187446594, pérdida = 0.046526765437071994\n",
            "Época 13150: b = -0.3803851008415222, w = 0.4196942448616028, pérdida = 0.038602375703954146\n",
            "Época 13200: b = -0.38033127784729004, w = 0.420051246881485, pérdida = 0.03998342489229105\n",
            "Época 13250: b = -0.38049638271331787, w = 0.4191642701625824, pérdida = 0.029751508325428805\n",
            "Época 13300: b = -0.3803768754005432, w = 0.4196065366268158, pérdida = 0.05288551231898523\n",
            "Época 13350: b = -0.38030752539634705, w = 0.4201756417751312, pérdida = 0.04512080838295752\n",
            "Época 13400: b = -0.38040000200271606, w = 0.41935697197914124, pérdida = 0.06024042540011413\n",
            "Época 13450: b = -0.38026267290115356, w = 0.41995102167129517, pérdida = 0.04386061411255308\n",
            "Época 13500: b = -0.3804185688495636, w = 0.4196476340293884, pérdida = 0.036274327098349726\n",
            "Época 13550: b = -0.38035333156585693, w = 0.4199354946613312, pérdida = 0.02868365508989858\n",
            "Época 13600: b = -0.3803219497203827, w = 0.42006996273994446, pérdida = 0.01895263489524891\n",
            "Época 13650: b = -0.38043367862701416, w = 0.41958075761795044, pérdida = 0.04755967354188867\n",
            "Época 13700: b = -0.3804389536380768, w = 0.4194248616695404, pérdida = 0.02938890242538734\n",
            "Época 13750: b = -0.38035449385643005, w = 0.4198299050331116, pérdida = 0.03653780275547134\n",
            "Época 13800: b = -0.3804265260696411, w = 0.4195288121700287, pérdida = 0.06112434372363468\n",
            "Época 13850: b = -0.3804057240486145, w = 0.41929537057876587, pérdida = 0.04629227793570001\n",
            "Época 13900: b = -0.3802470862865448, w = 0.4199383556842804, pérdida = 0.036297710104366304\n",
            "Época 13950: b = -0.38039958477020264, w = 0.4196169078350067, pérdida = 0.03347661149942615\n",
            "Época 14000: b = -0.380339115858078, w = 0.41996240615844727, pérdida = 0.06785370485013227\n",
            "Época 14050: b = -0.38036733865737915, w = 0.41952455043792725, pérdida = 0.022418174990606377\n",
            "Época 14100: b = -0.38022559881210327, w = 0.4202674925327301, pérdida = 0.05323823565761171\n",
            "Época 14150: b = -0.38039758801460266, w = 0.4198783040046692, pérdida = 0.05086332558735457\n",
            "Época 14200: b = -0.3804852366447449, w = 0.4197167158126831, pérdida = 0.05308889162406305\n",
            "Época 14250: b = -0.38046425580978394, w = 0.4198165237903595, pérdida = 0.05353421291480905\n",
            "Época 14300: b = -0.3804284334182739, w = 0.41978567838668823, pérdida = 0.023119885783924918\n",
            "Época 14350: b = -0.38054603338241577, w = 0.4192907214164734, pérdida = 0.03115335118497524\n",
            "Época 14400: b = -0.38049542903900146, w = 0.4196111857891083, pérdida = 0.05421676443812659\n",
            "Época 14450: b = -0.38046878576278687, w = 0.4194839298725128, pérdida = 0.038041772816561355\n",
            "Época 14500: b = -0.38037264347076416, w = 0.41980797052383423, pérdida = 0.0352918197161509\n",
            "Época 14550: b = -0.38033318519592285, w = 0.41974037885665894, pérdida = 0.040005215210576525\n",
            "Época 14600: b = -0.38037940859794617, w = 0.4194633662700653, pérdida = 0.03931547064158266\n",
            "Época 14650: b = -0.3802626132965088, w = 0.4196448028087616, pérdida = 0.0452436994575341\n",
            "Época 14700: b = -0.38024353981018066, w = 0.41976064443588257, pérdida = 0.03833008752528935\n",
            "Época 14750: b = -0.3802613914012909, w = 0.41979312896728516, pérdida = 0.05291094092412311\n",
            "Época 14800: b = -0.3801984488964081, w = 0.41988667845726013, pérdida = 0.027277987206188528\n",
            "Época 14850: b = -0.38025835156440735, w = 0.41979506611824036, pérdida = 0.04417380939262622\n",
            "Época 14900: b = -0.38028421998023987, w = 0.41976112127304077, pérdida = 0.04881541091637679\n",
            "Época 14950: b = -0.38023683428764343, w = 0.41998469829559326, pérdida = 0.052882797235788204\n",
            "Época 15000: b = -0.3803217113018036, w = 0.41957569122314453, pérdida = 0.04225107304887433\n",
            "Época 15050: b = -0.38032266497612, w = 0.419425368309021, pérdida = 0.04327073586703717\n",
            "Época 15100: b = -0.38023412227630615, w = 0.4200442135334015, pérdida = 0.06990217517152153\n",
            "Época 15150: b = -0.3803180754184723, w = 0.41972777247428894, pérdida = 0.060513926942062514\n",
            "Época 15200: b = -0.38037312030792236, w = 0.4193539023399353, pérdida = 0.03989239016532511\n",
            "Época 15250: b = -0.38031473755836487, w = 0.41951704025268555, pérdida = 0.04391427217906368\n",
            "Época 15300: b = -0.38029325008392334, w = 0.41974133253097534, pérdida = 0.05406584040135273\n",
            "Época 15350: b = -0.38037267327308655, w = 0.4195585548877716, pérdida = 0.032906648938824376\n",
            "Época 15400: b = -0.3803584575653076, w = 0.4196923077106476, pérdida = 0.021771633801171125\n",
            "Época 15450: b = -0.3804073929786682, w = 0.41952311992645264, pérdida = 0.03785581252537132\n",
            "Época 15500: b = -0.380351722240448, w = 0.4196600615978241, pérdida = 0.04606510953348217\n",
            "Época 15550: b = -0.380380779504776, w = 0.41958943009376526, pérdida = 0.05016872594104207\n",
            "Época 15600: b = -0.3803182542324066, w = 0.41961783170700073, pérdida = 0.0426860254653939\n",
            "Época 15650: b = -0.38021302223205566, w = 0.41996943950653076, pérdida = 0.04052872702127298\n",
            "Época 15700: b = -0.3802214562892914, w = 0.4199215769767761, pérdida = 0.04597368128670871\n",
            "Época 15750: b = -0.3802477717399597, w = 0.41963550448417664, pérdida = 0.04024716713371444\n",
            "Época 15800: b = -0.38030287623405457, w = 0.4195761978626251, pérdida = 0.07610196215228801\n",
            "Época 15850: b = -0.3802979588508606, w = 0.4195762872695923, pérdida = 0.05726360832426427\n",
            "Época 15900: b = -0.38032248616218567, w = 0.4195784032344818, pérdida = 0.048447063186351585\n",
            "Época 15950: b = -0.38027358055114746, w = 0.4197557270526886, pérdida = 0.037559924968077384\n",
            "Época 16000: b = -0.38029715418815613, w = 0.41950130462646484, pérdida = 0.06724369375661611\n",
            "Época 16050: b = -0.38028958439826965, w = 0.41945552825927734, pérdida = 0.04014504304192417\n",
            "Época 16100: b = -0.38021066784858704, w = 0.41965314745903015, pérdida = 0.031198643216790754\n",
            "Época 16150: b = -0.38018298149108887, w = 0.4197724759578705, pérdida = 0.06808193413513135\n",
            "Época 16200: b = -0.38018184900283813, w = 0.41967248916625977, pérdida = 0.034781073311040904\n",
            "Época 16250: b = -0.38024845719337463, w = 0.41953107714653015, pérdida = 0.03230180228912697\n",
            "Época 16300: b = -0.38026630878448486, w = 0.4195511043071747, pérdida = 0.035536114281290554\n",
            "Época 16350: b = -0.380231648683548, w = 0.41998594999313354, pérdida = 0.0336012990430149\n",
            "Época 16400: b = -0.38032475113868713, w = 0.419252872467041, pérdida = 0.05010336669915414\n",
            "Época 16450: b = -0.3802604377269745, w = 0.4192992150783539, pérdida = 0.04049495461285537\n",
            "Época 16500: b = -0.3802351951599121, w = 0.4196721315383911, pérdida = 0.06059738727560849\n",
            "Época 16550: b = -0.380295991897583, w = 0.4195578396320343, pérdida = 0.040184734795499\n",
            "Época 16600: b = -0.38022711873054504, w = 0.4198102653026581, pérdida = 0.050435004725578415\n",
            "Época 16650: b = -0.38027969002723694, w = 0.41970115900039673, pérdida = 0.046249918793370516\n",
            "Época 16700: b = -0.38023337721824646, w = 0.41968002915382385, pérdida = 0.055036886579840925\n",
            "Época 16750: b = -0.380202054977417, w = 0.4200003743171692, pérdida = 0.027281299193897286\n",
            "Época 16800: b = -0.38040024042129517, w = 0.4190376400947571, pérdida = 0.06104438413352667\n",
            "Época 16850: b = -0.3802221715450287, w = 0.4199046790599823, pérdida = 0.041697239286001636\n",
            "Época 16900: b = -0.380266010761261, w = 0.4197087287902832, pérdida = 0.06036491534163768\n",
            "Época 16950: b = -0.3802105188369751, w = 0.4199255704879761, pérdida = 0.03640297046749997\n",
            "Época 17000: b = -0.3802761733531952, w = 0.41973358392715454, pérdida = 0.06753676608572838\n",
            "Época 17050: b = -0.3803854286670685, w = 0.41931939125061035, pérdida = 0.03249325535643852\n",
            "Época 17100: b = -0.3803122639656067, w = 0.41981643438339233, pérdida = 0.049478775775126084\n",
            "Época 17150: b = -0.38048622012138367, w = 0.4194861948490143, pérdida = 0.029533195561233763\n",
            "Época 17200: b = -0.38033998012542725, w = 0.41975703835487366, pérdida = 0.021277114619714238\n",
            "Época 17250: b = -0.380359947681427, w = 0.4193606972694397, pérdida = 0.03162273169528671\n",
            "Época 17300: b = -0.3802393972873688, w = 0.419770747423172, pérdida = 0.05058429925022315\n",
            "Época 17350: b = -0.38028255105018616, w = 0.41961923241615295, pérdida = 0.08423990809933724\n",
            "Época 17400: b = -0.38026559352874756, w = 0.4196261465549469, pérdida = 0.04663467570531441\n",
            "Época 17450: b = -0.38019347190856934, w = 0.419761598110199, pérdida = 0.04848934279141593\n",
            "Época 17500: b = -0.3801928162574768, w = 0.41949543356895447, pérdida = 0.038874806857786964\n",
            "Época 17550: b = -0.3802073001861572, w = 0.4196418225765228, pérdida = 0.03810881646839714\n",
            "Época 17600: b = -0.3801472783088684, w = 0.4199875593185425, pérdida = 0.027420303195579716\n",
            "Época 17650: b = -0.38021230697631836, w = 0.4198912978172302, pérdida = 0.0497796670566461\n",
            "Época 17700: b = -0.3802604377269745, w = 0.419594407081604, pérdida = 0.05121042790345243\n",
            "Época 17750: b = -0.38025641441345215, w = 0.4198386073112488, pérdida = 0.037099561888773246\n",
            "Época 17800: b = -0.38033151626586914, w = 0.4197361171245575, pérdida = 0.045689740517097364\n",
            "Época 17850: b = -0.38031843304634094, w = 0.419821172952652, pérdida = 0.06621596449453078\n",
            "Época 17900: b = -0.38037392497062683, w = 0.4194912314414978, pérdida = 0.04946216694258332\n",
            "Época 17950: b = -0.3804287612438202, w = 0.4193718731403351, pérdida = 0.05324634996259381\n",
            "Época 18000: b = -0.38033315539360046, w = 0.41993018984794617, pérdida = 0.030039494549213452\n",
            "Época 18050: b = -0.3803611695766449, w = 0.4194985628128052, pérdida = 0.04670563167077831\n",
            "Época 18100: b = -0.3803575336933136, w = 0.41953954100608826, pérdida = 0.02261280443063804\n",
            "Época 18150: b = -0.380409300327301, w = 0.41962242126464844, pérdida = 0.04408642416014217\n",
            "Época 18200: b = -0.38038742542266846, w = 0.41971272230148315, pérdida = 0.04201517437229902\n",
            "Época 18250: b = -0.38035544753074646, w = 0.4199320077896118, pérdida = 0.0660453119497486\n",
            "Época 18300: b = -0.380276083946228, w = 0.4200891852378845, pérdida = 0.048346035035201795\n",
            "Época 18350: b = -0.38040003180503845, w = 0.4196099042892456, pérdida = 0.05773516354300773\n",
            "Época 18400: b = -0.3803134858608246, w = 0.420052170753479, pérdida = 0.08404089552493593\n",
            "Época 18450: b = -0.3804546594619751, w = 0.4194253385066986, pérdida = 0.04634217150010974\n",
            "Época 18500: b = -0.38039258122444153, w = 0.41978976130485535, pérdida = 0.057541510660336366\n",
            "Época 18550: b = -0.3803780972957611, w = 0.4199118912220001, pérdida = 0.06087542523886338\n",
            "Época 18600: b = -0.3804399073123932, w = 0.41956448554992676, pérdida = 0.0494605217781822\n",
            "Época 18650: b = -0.3803720772266388, w = 0.4200047552585602, pérdida = 0.06432194940247855\n",
            "Época 18700: b = -0.38030725717544556, w = 0.41997066140174866, pérdida = 0.03879771275302688\n",
            "Época 18750: b = -0.3804079592227936, w = 0.419583261013031, pérdida = 0.04637094075521645\n",
            "Época 18800: b = -0.3804451823234558, w = 0.4196312725543976, pérdida = 0.03177326620139229\n",
            "Época 18850: b = -0.38045477867126465, w = 0.4198462963104248, pérdida = 0.04500063493319528\n",
            "Época 18900: b = -0.3804887533187866, w = 0.4196217656135559, pérdida = 0.07082373686628517\n",
            "Época 18950: b = -0.38048702478408813, w = 0.419484943151474, pérdida = 0.04914517919333847\n",
            "Época 19000: b = -0.3804611563682556, w = 0.4197804927825928, pérdida = 0.020132631512520753\n",
            "Época 19050: b = -0.380428284406662, w = 0.4198586344718933, pérdida = 0.03215557572949593\n",
            "Época 19100: b = -0.3803579807281494, w = 0.4199562072753906, pérdida = 0.041316438535632945\n",
            "Época 19150: b = -0.3803614675998688, w = 0.41999635100364685, pérdida = 0.044977693781720764\n",
            "Época 19200: b = -0.38040250539779663, w = 0.41950157284736633, pérdida = 0.039815201155526656\n",
            "Época 19250: b = -0.3802950978279114, w = 0.41988110542297363, pérdida = 0.025044666897832024\n",
            "Época 19300: b = -0.38037240505218506, w = 0.41937634348869324, pérdida = 0.03074749211159386\n",
            "Época 19350: b = -0.3802815079689026, w = 0.419857919216156, pérdida = 0.05614872141142389\n",
            "Época 19400: b = -0.38029995560646057, w = 0.41984879970550537, pérdida = 0.03509895828011421\n",
            "Época 19450: b = -0.3801647126674652, w = 0.42005863785743713, pérdida = 0.049990501901002016\n",
            "Época 19500: b = -0.3802189826965332, w = 0.4199470579624176, pérdida = 0.03830738800396588\n",
            "Época 19550: b = -0.3802974224090576, w = 0.4197859764099121, pérdida = 0.06128829694980109\n",
            "Época 19600: b = -0.3802254796028137, w = 0.42011550068855286, pérdida = 0.03529152167230611\n",
            "Época 19650: b = -0.3803069293498993, w = 0.41973528265953064, pérdida = 0.04860010504577996\n",
            "Época 19700: b = -0.38037562370300293, w = 0.4196138083934784, pérdida = 0.053886569587095874\n",
            "Época 19750: b = -0.3803572654724121, w = 0.4196048676967621, pérdida = 0.021592720609881405\n",
            "Época 19800: b = -0.38031554222106934, w = 0.4198029339313507, pérdida = 0.05381795288134341\n",
            "Época 19850: b = -0.3803362548351288, w = 0.4194604456424713, pérdida = 0.039128121610578166\n",
            "Época 19900: b = -0.38027244806289673, w = 0.41989991068840027, pérdida = 0.0596533713745141\n",
            "Época 19950: b = -0.3802702724933624, w = 0.4199522137641907, pérdida = 0.054662280705893795\n",
            "Época 20000: b = -0.38028064370155334, w = 0.4199811816215515, pérdida = 0.03828802768023218\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simplificación\n"
      ],
      "metadata": {
        "id": "j_xud7vfu03o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Extraer las columnas usando NumPy\n",
        "import numpy as np\n",
        "x = np.array(df['petal length (cm)'])  # Definir x como petal length\n",
        "y = np.array(df['petal width (cm)'])   # Definir y como petal width\n",
        "\n",
        "# Mostrar los primeros valores\n",
        "print(\"x (Petal Length):\", x[:5])\n",
        "print(\"y (Petal Width):\", y[:5])\n",
        "\n",
        "# Mezcla los índices\n",
        "idx = np.arange(N)\n",
        "np.random.shuffle(idx)\n",
        "\n",
        "# Usa los primeros 80% de índices para entrenamiento\n",
        "train_idx = idx[:int(N * 0.8)]\n",
        "# Usa el 20% restante para validación\n",
        "val_idx = idx[int(N * 0.8):]\n",
        "\n",
        "# Generar los conjuntos de entrenamiento y validación\n",
        "x_train, y_train = x[train_idx], y[train_idx]\n",
        "x_val, y_val = x[val_idx], y[val_idx]\n",
        "\n",
        "# Mostrar tamaños de los conjuntos\n",
        "print(f\"Train set: {x_train.shape}, {y_train.shape}\")\n",
        "print(f\"Validation set: {x_val.shape}, {y_val.shape}\")\n",
        "\n",
        "x_train_tensor = torch.as_tensor(x_train)\n",
        "y_train_tensor = torch.as_tensor(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6rt-KkMuxmT",
        "outputId": "52f7f9e6-086a-4a1e-e5a1-b6e464e177ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x (Petal Length): [1.4 1.4 1.3 1.5 1.4]\n",
            "y (Petal Width): [0.2 0.2 0.2 0.2 0.2]\n",
            "Train set: (120,), (120,)\n",
            "Validation set: (30,), (30,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define el dispositivo (CPU o GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 1. Define la tasa de aprendizaje (eta)\n",
        "lr = 0.01\n",
        "\n",
        "# 2. Inicializa los parámetros \"b\" y \"w\" aleatoriamente\n",
        "torch.manual_seed(42)  # Para reproducibilidad\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "w = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "\n",
        "# 3. Define un optimizador SGD para actualizar los parámetros\n",
        "optimizer = optim.SGD([b, w], lr=lr)\n",
        "\n",
        "# 4. Define el número de épocas\n",
        "n_epochs = 10000\n",
        "\n",
        "# 5. Bucle de entrenamiento\n",
        "for epoch in range(n_epochs):\n",
        "    # Paso 1 - Calcula la salida predicha por el modelo (forward pass)\n",
        "    yhat = b + w * x_train_tensor\n",
        "\n",
        "    # Paso 2 - Calcula la pérdida\n",
        "    # Estamos usando TODOS los puntos de datos, por lo que esto es\n",
        "    # Gradiente Descendente por Lotes (Batch Gradient Descent).\n",
        "    error = (yhat - y_train_tensor)\n",
        "    # Es una regresión, por lo que calculamos el error cuadrático medio (MSE)\n",
        "    loss = (error ** 2).mean()\n",
        "\n",
        "    # Paso 3 - Calcula los gradientes para los parámetros \"b\" y \"w\"\n",
        "    loss.backward()\n",
        "\n",
        "    # Paso 4 - Actualiza los parámetros usando los gradientes y\n",
        "    # la tasa de aprendizaje. ¡No más actualización manual!\n",
        "    # Step 4 - Updates parameters using gradients and\n",
        "    # the learning rate. No more manual update!\n",
        "    # with torch.no_grad():\n",
        "    # b -= lr * b.grad\n",
        "    # w -= lr * w.grad\n",
        "    optimizer.step()\n",
        "\n",
        "    # Paso 5 - Limpia los gradientes para la siguiente iteración\n",
        "    optimizer.zero_grad()\n",
        "    # No more telling Pytorch to let gradients go!\n",
        "    # b.grad.zero_()\n",
        "    # w.grad.zero_()\n",
        "\n",
        "# 6. Imprime los parámetros finales\n",
        "print(f\"Parámetro b: {b.item()}\")\n",
        "print(f\"Parámetro w: {w.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdrzUnQPu42b",
        "outputId": "ffcf07a7-71f9-4103-a01f-f0c1cbbe2e32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parámetro b: -0.3803756535053253\n",
            "Parámetro w: 0.4197814166545868\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Definición de función de perdida\n",
        "\n"
      ],
      "metadata": {
        "id": "D2YKwN8lvpub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn  # Importa el módulo nn para usar MSELoss\n",
        "import torch\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "o-saBUlTvniU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.MSELoss(reduction='mean')\n",
        "# This is a random example to illustrate the loss function\n",
        "predictions = torch.tensor([0.5, 1.0])\n",
        "labels = torch.tensor([2.0, 1.3])\n",
        "loss_fn(predictions, labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NRysLNAwS1r",
        "outputId": "f22c4bb7-31b2-4cf2-c59d-91ed7f1ffcf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.1700)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "# Define el dispositivo (CPU o GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "torch.manual_seed(42)  # Para reproducibilidad\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "w = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "\n",
        "# 2. Inicializa los parámetros \"b\" y \"w\" aleatoriamente\n",
        "\n",
        "# Define el dispositivo (CPU o GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 1. Define la tasa de aprendizaje (eta)\n",
        "lr = 0.01\n",
        "\n",
        "# 2. Inicializa los parámetros \"b\" y \"w\" aleatoriamente\n",
        "torch.manual_seed(42)  # Para reproducibilidad\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "w = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "\n",
        "# 3. Define un optimizador y un error SGD para actualizar los parámetros\n",
        "optimizer = optim.SGD([b, w], lr=lr)\n",
        "\n",
        "# Defines an MSE loss function\n",
        "loss_fn = nn.MSELoss(reduction='mean')\n",
        "\n",
        "# 4. Define el número de épocas\n",
        "n_epochs = 10000\n",
        "\n",
        "# 5. Bucle de entrenamiento\n",
        "for epoch in range(n_epochs):\n",
        "    # Paso 1 - Calcula la salida predicha por el modelo (forward pass)\n",
        "    yhat = b + w * x_train_tensor\n",
        "\n",
        "    # Paso 2 - Calcula la pérdida\n",
        "    # Estamos usando TODOS los puntos de datos, por lo que esto es\n",
        "    # Gradiente Descendente por Lotes (Batch Gradient Descent).\n",
        "    # error = (yhat - y_train_tensor)\n",
        "    # Es una regresión, por lo que calculamos el error cuadrático medio (MSE)\n",
        "    # loss = (error ** 2).mean()\n",
        "\n",
        "    loss = loss_fn(yhat, y_train_tensor)\n",
        "\n",
        "    # Paso 3 - Calcula los gradientes para los parámetros \"b\" y \"w\"\n",
        "    loss.backward()\n",
        "\n",
        "    # Paso 4 - Actualiza los parámetros usando los gradientes y\n",
        "    # la tasa de aprendizaje. ¡No más actualización manual!\n",
        "    # Step 4 - Updates parameters using gradients and\n",
        "    # the learning rate. No more manual update!\n",
        "    # with torch.no_grad():\n",
        "    # b -= lr * b.grad\n",
        "    # w -= lr * w.grad\n",
        "    optimizer.step()\n",
        "\n",
        "    # Paso 5 - Limpia los gradientes para la siguiente iteración\n",
        "    optimizer.zero_grad()\n",
        "    # No more telling Pytorch to let gradients go!\n",
        "    # b.grad.zero_()\n",
        "    # w.grad.zero_()\n",
        "\n",
        "# 6. Imprime los parámetros finales\n",
        "print(f\"Parámetro b: {b.item()}\")\n",
        "print(f\"Parámetro w: {w.item()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKRhd7J2wlZN",
        "outputId": "d1ef3bc0-f925-4831-81e0-0e6e598b00c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parámetro b: -0.3803756535053253\n",
            "Parámetro w: 0.4197814166545868\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Incluir el modelo\n"
      ],
      "metadata": {
        "id": "HMGws6zBw9W4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class ManualLinearRegression(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Define los parámetros \"b\" y \"w\" como nn.Parameter\n",
        "        self.b = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
        "        self.w = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Calcula la salida/predicción del modelo\n",
        "        return self.b + self.w * x\n"
      ],
      "metadata": {
        "id": "qrU10xCew7Df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "# Creates a \"dummy\" instance of our ManualLinearRegression model\n",
        "dummy = ManualLinearRegression()\n",
        "list(dummy.parameters()) # Método heredado de nn.Module"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ph6yg_-zxwie",
        "outputId": "dac362c7-2ce8-48f2-e301-80664940162f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([0.3367], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([0.1288], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "# Define el dispositivo (CPU o GPU)\n",
        "# Define el dispositivo (CPU o GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 1. Define la tasa de aprendizaje (eta)\n",
        "lr = 0.01\n",
        "\n",
        "# 2. Inicializa los parámetros \"b\" y \"w\" aleatoriamente\n",
        "torch.manual_seed(42)  # Para reproducibilidad\n",
        "# Ya no se requiere inicializar b y w, están dentro de la clase\n",
        "#b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "#w = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "# Inicializo modelo\n",
        "model = ManualLinearRegression()\n",
        "print(model.state_dict())\n",
        "\n",
        "# 3. Define un optimizador y un error SGD para actualizar los parámetros\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "#optimizer = optim.SGD([b, w], lr=lr)\n",
        "\n",
        "# Defines an MSE loss function\n",
        "loss_fn = nn.MSELoss(reduction='mean')\n",
        "\n",
        "# 4. Define el número de épocas\n",
        "n_epochs = 10000\n",
        "\n",
        "# 5. Bucle de entrenamiento\n",
        "for epoch in range(n_epochs):\n",
        "    # Paso 1 - Calcula la salida predicha por el modelo (forward pass)\n",
        "    # Ya no se corre lo siguiente:\n",
        "    # yhat = b + w * x_train_tensor\n",
        "    model.train() # set the model to training mode\n",
        "    yhat = model(x_train_tensor)\n",
        "\n",
        "    # Paso 2 - Calcula la pérdida\n",
        "    # Estamos usando TODOS los puntos de datos, por lo que esto es\n",
        "    # Gradiente Descendente por Lotes (Batch Gradient Descent).\n",
        "    # error = (yhat - y_train_tensor)\n",
        "    # Es una regresión, por lo que calculamos el error cuadrático medio (MSE)\n",
        "    # loss = (error ** 2).mean()\n",
        "\n",
        "    loss = loss_fn(yhat, y_train_tensor)\n",
        "\n",
        "    # Paso 3 - Calcula los gradientes para los parámetros \"b\" y \"w\"\n",
        "    loss.backward()\n",
        "\n",
        "    # Paso 4 - Actualiza los parámetros usando los gradientes y\n",
        "    # la tasa de aprendizaje. ¡No más actualización manual!\n",
        "    # Step 4 - Updates parameters using gradients and\n",
        "    # the learning rate. No more manual update!\n",
        "    # with torch.no_grad():\n",
        "    # b -= lr * b.grad\n",
        "    # w -= lr * w.grad\n",
        "    optimizer.step()\n",
        "\n",
        "    # Paso 5 - Limpia los gradientes para la siguiente iteración\n",
        "    optimizer.zero_grad()\n",
        "    # No more telling Pytorch to let gradients go!\n",
        "    # b.grad.zero_()\n",
        "    # w.grad.zero_()\n",
        "\n",
        "print(model.state_dict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXuI3N9iyPGT",
        "outputId": "d780fe9b-7197-4d57-bffa-faefccdc7271"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('b', tensor([0.3367])), ('w', tensor([0.1288]))])\n",
            "OrderedDict([('b', tensor([-0.3804])), ('w', tensor([0.4198]))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# En la practica"
      ],
      "metadata": {
        "id": "fooT_rOQy8jx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "linear = nn.Linear(1, 1)\n",
        "print(linear)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhL1BO7yy5Um",
        "outputId": "99eead08-d600-47f4-ebed-5bd5ba25b6b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear(in_features=1, out_features=1, bias=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyLinearRegression(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # Instead of our custom parameters, we use a Linear model\n",
        "    # with a single input and a single output\n",
        "    self.linear = nn.Linear(1, 1)\n",
        "    def forward(self, x):\n",
        "    # Now it only makes\n",
        "      self.linear(x)"
      ],
      "metadata": {
        "id": "_oh1rGj-y4j4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "dummy = MyLinearRegression()\n",
        "list(dummy.parameters())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjQDE8Gwzhnl",
        "outputId": "ae4b7c18-40c8-46a8-ad99-0916d7ae8919"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[0.7645]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([0.8300], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_tensor = torch.as_tensor(x_train, dtype=torch.float32, device=device).reshape(-1, 1)\n",
        "y_train_tensor = torch.as_tensor(y_train, dtype=torch.float32, device=device).reshape(-1, 1)"
      ],
      "metadata": {
        "id": "rji5nr5TznEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "# Define el dispositivo (CPU o GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 1. Define la tasa de aprendizaje (eta)\n",
        "lr = 0.01\n",
        "\n",
        "# 2. Inicializa los parámetros \"b\" y \"w\" aleatoriamente\n",
        "torch.manual_seed(42)  # Para reproducibilidad\n",
        "\n",
        "# Inicializo modelo\n",
        "model = nn.Sequential(nn.Linear(1, 1)).to(device)  # Mueve el modelo al dispositivo\n",
        "\n",
        "# Imprime el estado inicial del modelo\n",
        "print(\"Estado inicial del modelo:\")\n",
        "print(model.state_dict())\n",
        "\n",
        "# 3. Define un optimizador y un error SGD para actualizar los parámetros\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "# Define una función de pérdida MSE\n",
        "loss_fn = nn.MSELoss(reduction='mean')\n",
        "\n",
        "# 4. Define el número de épocas\n",
        "n_epochs = 10000\n",
        "\n",
        "# 5. Bucle de entrenamiento\n",
        "for epoch in range(n_epochs):\n",
        "    # Paso 1 - Calcula la salida predicha por el modelo (forward pass)\n",
        "    model.train()  # Establece el modelo en modo de entrenamiento\n",
        "    yhat = model(x_train_tensor)\n",
        "\n",
        "    # Paso 2 - Calcula la pérdida\n",
        "    loss = loss_fn(yhat, y_train_tensor)\n",
        "\n",
        "    # Paso 3 - Calcula los gradientes para los parámetros \"b\" y \"w\"\n",
        "    loss.backward()\n",
        "\n",
        "    # Paso 4 - Actualiza los parámetros usando los gradientes y la tasa de aprendizaje\n",
        "    optimizer.step()\n",
        "\n",
        "    # Paso 5 - Limpia los gradientes para la siguiente iteración\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "# Imprime el estado final del modelo\n",
        "print(\"\\nEstado final del modelo:\")\n",
        "print(model.state_dict())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqXCE_OCzsW0",
        "outputId": "a3d4437e-35fa-4ed5-a8b5-628dde23ed06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estado inicial del modelo:\n",
            "OrderedDict([('0.weight', tensor([[0.7645]])), ('0.bias', tensor([0.8300]))])\n",
            "\n",
            "Estado final del modelo:\n",
            "OrderedDict([('0.weight', tensor([[0.4179]])), ('0.bias', tensor([-0.3781]))])\n"
          ]
        }
      ]
    }
  ]
}