{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnOSLtz3HnXN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load and prepare the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = (iris.target == 0).astype(float)  # Setosa = 1, others = 0\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Convert to torch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos el modelo"
      ],
      "metadata": {
        "id": "fmtzNfFGIDMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(4, 1),    # 4 features in Iris\n",
        "    nn.Sigmoid()        # for binary classification\n",
        ")"
      ],
      "metadata": {
        "id": "Hq-W0fM4H-wy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Cargar y preparar el dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = (iris.target == 0).astype(float)  # Setosa = 1, otros = 0\n",
        "\n",
        "# Dividir y normalizar\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Convertir a tensores\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# Definir el modelo con nn.Sequential\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(4, 1),    # 4 entradas → 1 salida\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "# Acceder a la capa lineal\n",
        "linear = model[0]\n",
        "\n",
        "# Pesos y sesgo iniciales\n",
        "print(\"🔹 Pesos iniciales:\", linear.weight.data.numpy())\n",
        "print(\"🔹 Sesgo inicial:\", linear.bias.data.numpy())\n",
        "\n",
        "# Entrenamiento\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "for epoch in range(100):\n",
        "    y_pred = model(X_train)\n",
        "    loss = criterion(y_pred, y_train)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch {epoch}: Loss = {loss.item():.4f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZkBk-msIFmJ",
        "outputId": "4eb8fc1b-a98a-4749-9e1f-8b9066b836e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔹 Pesos iniciales: [[-0.02050364  0.36662245  0.44898343  0.3318243 ]]\n",
            "🔹 Sesgo inicial: [0.29767668]\n",
            "Epoch 0: Loss = 1.0295\n",
            "Epoch 10: Loss = 0.4599\n",
            "Epoch 20: Loss = 0.2864\n",
            "Epoch 30: Loss = 0.2107\n",
            "Epoch 40: Loss = 0.1683\n",
            "Epoch 50: Loss = 0.1410\n",
            "Epoch 60: Loss = 0.1219\n",
            "Epoch 70: Loss = 0.1076\n",
            "Epoch 80: Loss = 0.0965\n",
            "Epoch 90: Loss = 0.0877\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pesos y sesgo finales\n",
        "print(\"\\n Pesos finales:\", linear.weight.data.numpy())\n",
        "print(\" Sesgo final:\", linear.bias.data.numpy())"
      ],
      "metadata": {
        "id": "_eCI0qMXJBFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imprime el estado final del modelo\n",
        "print(\"\\nEstado final del modelo:\")\n",
        "print(linear.state_dict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "My9GbKWtJq7S",
        "outputId": "5b6e9410-ae85-430a-ba8e-3f81a20a60ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Estado final del modelo:\n",
            "OrderedDict([('weight', tensor([[-0.8850,  1.1452, -0.8244, -0.9039]])), ('bias', tensor([-0.6811]))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluación\n",
        "with torch.no_grad():\n",
        "    y_pred_test = model(X_test)\n",
        "    acc = (y_pred_test > 0.5).float().eq(y_test).float().mean()\n",
        "    print(f\"\\n Accuracy en test: {acc:.4f}\")\n",
        "\n",
        "# Pesos y sesgo finales\n",
        "print(\"\\n Pesos finales:\", linear.weight.data.numpy())\n",
        "print(\" Sesgo final:\", linear.bias.data.numpy())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KD42oJXDINgm",
        "outputId": "dcb3f317-34f7-40a1-9d80-6e40077ef022"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Accuracy en test: 1.0000\n",
            "\n",
            "🔸 Pesos finales: [[-0.8850252   1.1451691  -0.8243631  -0.90389013]]\n",
            "🔸 Sesgo final: [-0.6811251]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Como se hace en la vida real"
      ],
      "metadata": {
        "id": "BpDDOL6NKb_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# 1. Load and preprocess data\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = (iris.target == 0).astype(float)  # Setosa = 1, others = 0\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n"
      ],
      "metadata": {
        "id": "ZUI9smS2Kezi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos modelo sin sigmoid"
      ],
      "metadata": {
        "id": "uXk9OqlSKquO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(4, 1)  # No sigmoid here\n",
        ")\n"
      ],
      "metadata": {
        "id": "lntVPWc_KgyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "# Save initial weights\n",
        "linear = model[0]\n",
        "initial_weights = linear.weight.data.clone()\n",
        "initial_bias = linear.bias.data.clone()"
      ],
      "metadata": {
        "id": "5wBzQTQEKup2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(100):\n",
        "    logits = model(X_train)           # raw outputs (logits)\n",
        "    loss = criterion(logits, y_train) # BCEWithLogitsLoss includes sigmoid\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch {epoch}: Loss = {loss.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thKEQ6luKyXw",
        "outputId": "b04de4eb-b74f-4712-9d6a-d341d49c2465"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Loss = 0.8947\n",
            "Epoch 10: Loss = 0.4257\n",
            "Epoch 20: Loss = 0.2740\n",
            "Epoch 30: Loss = 0.2045\n",
            "Epoch 40: Loss = 0.1645\n",
            "Epoch 50: Loss = 0.1383\n",
            "Epoch 60: Loss = 0.1196\n",
            "Epoch 70: Loss = 0.1057\n",
            "Epoch 80: Loss = 0.0948\n",
            "Epoch 90: Loss = 0.0861\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    logits_test = model(X_test)\n",
        "    y_pred = torch.sigmoid(logits_test)   # now apply sigmoid manually to interpret as probabilities\n",
        "    y_pred_labels = (y_pred > 0.5).float()\n",
        "    acc = (y_pred_labels == y_test).float().mean()\n",
        "    print(f\"\\n Accuracy on test set: {acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_yyPgBcK21n",
        "outputId": "a4fc4d27-aab6-4406-b252-17ead53030f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Accuracy on test set: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names = iris.feature_names\n",
        "\n",
        "print(\"\\n Initial Coefficients:\")\n",
        "for name, w in zip(feature_names, initial_weights.numpy().flatten()):\n",
        "    print(f\"{name:20s}: {w:.4f}\")\n",
        "print(f\"{'Initial Bias':20s}: {initial_bias.item():.4f}\")\n",
        "\n",
        "print(\"\\n Final Coefficients:\")\n",
        "for name, w in zip(feature_names, linear.weight.data.numpy().flatten()):\n",
        "    print(f\"{name:20s}: {w:.4f}\")\n",
        "print(f\"{'Final Bias':20s}: {linear.bias.data.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzAqkn07K5Tb",
        "outputId": "59210fdf-ae3a-41db-adde-31ccfc9499d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Initial Coefficients:\n",
            "sepal length (cm)   : -0.4017\n",
            "sepal width (cm)    : -0.3250\n",
            "petal length (cm)   : 0.0774\n",
            "petal width (cm)    : 0.4760\n",
            "Initial Bias        : -0.2111\n",
            "\n",
            " Final Coefficients:\n",
            "sepal length (cm)   : -0.9957\n",
            "sepal width (cm)    : 0.8673\n",
            "petal length (cm)   : -1.0925\n",
            "petal width (cm)    : -0.6556\n",
            "Final Bias          : -0.8971\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regresion multinomial"
      ],
      "metadata": {
        "id": "u7H7tQ-7LpCF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ojo con la separaci[on lineal"
      ],
      "metadata": {
        "id": "Y6bBt-V4QrtE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Cargar y preparar el dataset\n",
        "iris = load_iris()\n",
        "X = iris.data                # shape: (150, 4)\n",
        "y = iris.target              # valores: 0 = Setosa, 1 = Versicolor, 2 = Virginica\n",
        "\n",
        "# Dividir y escalar\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Convertir a tensores\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)  # ⬅️ importante: enteros, no one-hot\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)\n"
      ],
      "metadata": {
        "id": "t0bwZvvsOCJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(4, 3)  # 4 features → 3 clases\n",
        ")"
      ],
      "metadata": {
        "id": "lrtpyb1iOEfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()  # ya incluye softmax + cross entropy\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)"
      ],
      "metadata": {
        "id": "RleQqerOOHDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(100):\n",
        "    modelo = model(X_train)          # shape: (batch_size, 3)\n",
        "    loss = criterion(modelo, y_train)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inTUl9QDOSHL",
        "outputId": "4b68d4a0-9e58-4e69-8c7e-7f995960f59e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 1.1492\n",
            "Epoch 10, Loss: 0.6398\n",
            "Epoch 20, Loss: 0.5084\n",
            "Epoch 30, Loss: 0.4481\n",
            "Epoch 40, Loss: 0.4118\n",
            "Epoch 50, Loss: 0.3866\n",
            "Epoch 60, Loss: 0.3676\n",
            "Epoch 70, Loss: 0.3524\n",
            "Epoch 80, Loss: 0.3397\n",
            "Epoch 90, Loss: 0.3288\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    logits_test = model(X_test)\n",
        "    y_pred = torch.argmax(logits_test, dim=1)\n",
        "    probs = F.softmax(logits_test, dim=1)                # probabilidades por clase\n",
        "\n",
        "    accuracy = (y_pred == y_test).float().mean()\n",
        "    print(f\"\\n Accuracy on test set: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCs84FuoOsHs",
        "outputId": "00bcbca3-63b9-4cd2-a642-4c720277981d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Accuracy on test set: 0.9667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{'Index':<5} {'P(Setosa)':<12} {'P(Versicolor)':<15} {'P(Virginica)':<13} {'Predicho':<12} {'Real':<8}\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "for i in range(len(X_test)):\n",
        "    p = probs[i].numpy()\n",
        "\n",
        "    pred_idx = int(y_pred[i].item())    # ✅ asegúrate de que sea int\n",
        "    real_idx = int(y_test[i].item())    # ✅ asegúrate de que sea int\n",
        "\n",
        "    pred = target_names[pred_idx]\n",
        "    real = target_names[real_idx]\n",
        "\n",
        "    print(f\"{i:<5} {p[0]:<12.4f} {p[1]:<15.4f} {p[2]:<13.4f} {pred:<12} {real:<8}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyIREPpGO6rJ",
        "outputId": "35358536-ce5b-4f49-b2fa-5705868a119d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index P(Setosa)    P(Versicolor)   P(Virginica)  Predicho     Real    \n",
            "----------------------------------------------------------------------\n",
            "0     0.0694       0.6141          0.3165        versicolor   versicolor\n",
            "1     0.9592       0.0381          0.0027        setosa       setosa  \n",
            "2     0.0001       0.1080          0.8919        virginica    virginica\n",
            "3     0.0705       0.5111          0.4184        versicolor   versicolor\n",
            "4     0.0205       0.5642          0.4153        versicolor   versicolor\n",
            "5     0.9095       0.0867          0.0039        setosa       setosa  \n",
            "6     0.2170       0.5814          0.2016        versicolor   versicolor\n",
            "7     0.0048       0.1625          0.8327        virginica    virginica\n",
            "8     0.0092       0.7402          0.2506        versicolor   versicolor\n",
            "9     0.1095       0.6969          0.1936        versicolor   versicolor\n",
            "10    0.0191       0.2089          0.7720        virginica    virginica\n",
            "11    0.9016       0.0968          0.0016        setosa       setosa  \n",
            "12    0.9403       0.0578          0.0019        setosa       setosa  \n",
            "13    0.9136       0.0848          0.0016        setosa       setosa  \n",
            "14    0.9821       0.0169          0.0011        setosa       setosa  \n",
            "15    0.0890       0.3281          0.5829        virginica    versicolor\n",
            "16    0.0046       0.1415          0.8539        virginica    virginica\n",
            "17    0.0931       0.7646          0.1423        versicolor   versicolor\n",
            "18    0.1064       0.5824          0.3111        versicolor   versicolor\n",
            "19    0.0041       0.1933          0.8026        virginica    virginica\n",
            "20    0.9419       0.0566          0.0016        setosa       setosa  \n",
            "21    0.0361       0.3345          0.6294        virginica    virginica\n",
            "22    0.9422       0.0552          0.0026        setosa       setosa  \n",
            "23    0.0052       0.2181          0.7768        virginica    virginica\n",
            "24    0.0034       0.0548          0.9418        virginica    virginica\n",
            "25    0.0047       0.1708          0.8245        virginica    virginica\n",
            "26    0.0030       0.3641          0.6330        virginica    virginica\n",
            "27    0.0034       0.0943          0.9023        virginica    virginica\n",
            "28    0.8819       0.1156          0.0025        setosa       setosa  \n",
            "29    0.9131       0.0848          0.0020        setosa       setosa  \n"
          ]
        }
      ]
    }
  ]
}